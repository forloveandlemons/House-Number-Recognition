{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TensorFlow with GPU",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "BlmQIFSLZDdc"
      },
      "cell_type": "markdown",
      "source": [
        "# Confirm TensorFlow can see the GPU\n",
        "\n",
        "Simply select \"GPU\" in the Accelerator drop-down in Notebook Settings (either through the Edit menu or the command palette at cmd/ctrl-shift-P)."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3IEVK-KFxi5Z",
        "outputId": "45ca44d2-613c-4f4c-e18d-1285b2644f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WkLjp1WGS5L1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "from IPython.display import display, Image\n",
        "from scipy import ndimage\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "from six.moves import cPickle as pickle\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QXRh0DPiZRyG"
      },
      "cell_type": "markdown",
      "source": [
        "# Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "metadata": {
        "id": "WagCYY5cS7tz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = 'http://ufldl.stanford.edu/housenumbers/'\n",
        "last_percent_reported = None\n",
        "# \n",
        "def download_progress_hook(count, blockSize, totalSize):\n",
        "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
        "  slow internet connections. Reports every 1% change in download progress.\n",
        "  \"\"\"\n",
        "  global last_percent_reported\n",
        "  percent = int(count * blockSize * 100 / totalSize)\n",
        "\n",
        "  if last_percent_reported != percent:\n",
        "    if percent % 5 == 0:\n",
        "      sys.stdout.write(\"%s%%\" % percent)\n",
        "      sys.stdout.flush()\n",
        "    else:\n",
        "      sys.stdout.write(\".\")\n",
        "      sys.stdout.flush()\n",
        "      \n",
        "    last_percent_reported = percent\n",
        "        \n",
        "def maybe_download(filename, force=False):\n",
        "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
        "  if force or not os.path.exists(filename):\n",
        "    print('Attempting to download:', filename) \n",
        "    filename, _ = urlretrieve(url + filename, filename, reporthook=download_progress_hook)\n",
        "    print('\\nDownload Complete!')\n",
        "  statinfo = os.stat(filename)\n",
        "  return filename\n",
        "\n",
        "train_filename = maybe_download('train.tar.gz')\n",
        "test_filename = maybe_download('test.tar.gz')\n",
        "extra_filename = maybe_download('extra.tar.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cxA2pIvqTA23",
        "colab_type": "code",
        "outputId": "b205b90d-06b6-4f2f-8d2c-50b7620a67e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(133)\n",
        "\n",
        "def maybe_extract(filename, force=False):\n",
        "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
        "  if os.path.isdir(root) and not force:\n",
        "    # You may override by setting force=True.\n",
        "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
        "  else:\n",
        "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
        "    tar = tarfile.open(filename)\n",
        "    sys.stdout.flush()\n",
        "    tar.extractall()\n",
        "    tar.close()\n",
        "  data_folders = root\n",
        "  print(data_folders)\n",
        "  return data_folders\n",
        "  \n",
        "train_folders = maybe_extract(train_filename)\n",
        "test_folders = maybe_extract(test_filename)\n",
        "extra_folders = maybe_extract(extra_filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train already present - Skipping extraction of train.tar.gz.\n",
            "train\n",
            "test already present - Skipping extraction of test.tar.gz.\n",
            "test\n",
            "extra already present - Skipping extraction of extra.tar.gz.\n",
            "extra\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GsqUPXPuTlpQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "# The DigitStructFile is just a wrapper around the h5py data.  It basically references \n",
        "#    inf:              The input h5 matlab file\n",
        "#    digitStructName   The h5 ref to all the file names\n",
        "#    digitStructBbox   The h5 ref to all struc data\n",
        "class DigitStructFile:\n",
        "    def __init__(self, inf):\n",
        "        self.inf = h5py.File(inf, 'r')\n",
        "        self.digitStructName = self.inf['digitStruct']['name']\n",
        "        self.digitStructBbox = self.inf['digitStruct']['bbox']\n",
        "    def getName(self,n):\n",
        "        # getName returns the 'name' string for for the n(th) digitStruct. \n",
        "        return ''.join([chr(c[0]) for c in self.inf[self.digitStructName[n][0]].value])\n",
        "\n",
        "    def bboxHelper(self,attr):\n",
        "        # bboxHelper handles the coding difference when there is exactly one bbox or an array of bbox.\n",
        "        if (len(attr) > 1):\n",
        "            attr = [self.inf[attr[j][0]][0][0] for j in range(len(attr))]\n",
        "        else:\n",
        "            attr = [attr[0][0]]\n",
        "        return attr\n",
        "\n",
        "    def getBbox(self,n):\n",
        "        # getBbox returns a dict of data for the n(th) bbox.\n",
        "        bbox = {}\n",
        "        bb = self.digitStructBbox[n].item()\n",
        "        bbox['height'] = self.bboxHelper(self.inf[bb][\"height\"])\n",
        "        bbox['label'] = self.bboxHelper(self.inf[bb][\"label\"])\n",
        "        bbox['left'] = self.bboxHelper(self.inf[bb][\"left\"])\n",
        "        bbox['top'] = self.bboxHelper(self.inf[bb][\"top\"])\n",
        "        bbox['width'] = self.bboxHelper(self.inf[bb][\"width\"])\n",
        "        return bbox\n",
        "\n",
        "    def getDigitStructure(self,n):\n",
        "        s = self.getBbox(n)\n",
        "        s['name']=self.getName(n)\n",
        "        return s\n",
        "\n",
        "    def getAllDigitStructure(self):\n",
        "        # getAllDigitStructure returns all the digitStruct from the input file.\n",
        "        result = []\n",
        "        for i in range(len(self.digitStructName)):\n",
        "            if (i % 1000 == 0):\n",
        "                print(i)\n",
        "            image_data = self.getDigitStructure(i)\n",
        "            figures = []\n",
        "            item = {\"filename\": image_data[\"name\"]}\n",
        "            for j in range(len(image_data[\"height\"])):\n",
        "                temp = [image_data[\"label\"][j],\n",
        "                        image_data[\"height\"][j], \n",
        "                        image_data[\"left\"][j], \n",
        "                        image_data[\"top\"][j], \n",
        "                        image_data[\"width\"][j]]\n",
        "                figures.append(temp)\n",
        "            item['boxes'] = figures\n",
        "            result.append(item)\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HgAE1MeMTqtP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "train_folders = 'train'\n",
        "test_folders = 'test'\n",
        "extra_folders = 'extra'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jrpxlPx7TtyJ",
        "colab_type": "code",
        "outputId": "c1b72814-790e-4384-fe9d-1900c3fd8863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "fin = os.path.join(train_folders, 'digitStruct.mat')\n",
        "dsf = DigitStructFile(fin)\n",
        "train_data = dsf.getAllDigitStructure()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cY6Vmns0Ubmg",
        "colab_type": "code",
        "outputId": "318f1662-8a4e-4ea8-b5fd-498e6dedb0dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "fin = os.path.join(test_folders, 'digitStruct.mat')\n",
        "dsf = DigitStructFile(fin)\n",
        "test_data = dsf.getAllDigitStructure()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XAxXE5-oUfgi",
        "colab_type": "code",
        "outputId": "2059096c-be67-4aa8-9c6b-507056a54c71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3468
        }
      },
      "cell_type": "code",
      "source": [
        "fin = os.path.join(extra_folders, 'digitStruct.mat')\n",
        "dsf = DigitStructFile(fin)\n",
        "extra_data = dsf.getAllDigitStructure()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "50000\n",
            "51000\n",
            "52000\n",
            "53000\n",
            "54000\n",
            "55000\n",
            "56000\n",
            "57000\n",
            "58000\n",
            "59000\n",
            "60000\n",
            "61000\n",
            "62000\n",
            "63000\n",
            "64000\n",
            "65000\n",
            "66000\n",
            "67000\n",
            "68000\n",
            "69000\n",
            "70000\n",
            "71000\n",
            "72000\n",
            "73000\n",
            "74000\n",
            "75000\n",
            "76000\n",
            "77000\n",
            "78000\n",
            "79000\n",
            "80000\n",
            "81000\n",
            "82000\n",
            "83000\n",
            "84000\n",
            "85000\n",
            "86000\n",
            "87000\n",
            "88000\n",
            "89000\n",
            "90000\n",
            "91000\n",
            "92000\n",
            "93000\n",
            "94000\n",
            "95000\n",
            "96000\n",
            "97000\n",
            "98000\n",
            "99000\n",
            "100000\n",
            "101000\n",
            "102000\n",
            "103000\n",
            "104000\n",
            "105000\n",
            "106000\n",
            "107000\n",
            "108000\n",
            "109000\n",
            "110000\n",
            "111000\n",
            "112000\n",
            "113000\n",
            "114000\n",
            "115000\n",
            "116000\n",
            "117000\n",
            "118000\n",
            "119000\n",
            "120000\n",
            "121000\n",
            "122000\n",
            "123000\n",
            "124000\n",
            "125000\n",
            "126000\n",
            "127000\n",
            "128000\n",
            "129000\n",
            "130000\n",
            "131000\n",
            "132000\n",
            "133000\n",
            "134000\n",
            "135000\n",
            "136000\n",
            "137000\n",
            "138000\n",
            "139000\n",
            "140000\n",
            "141000\n",
            "142000\n",
            "143000\n",
            "144000\n",
            "145000\n",
            "146000\n",
            "147000\n",
            "148000\n",
            "149000\n",
            "150000\n",
            "151000\n",
            "152000\n",
            "153000\n",
            "154000\n",
            "155000\n",
            "156000\n",
            "157000\n",
            "158000\n",
            "159000\n",
            "160000\n",
            "161000\n",
            "162000\n",
            "163000\n",
            "164000\n",
            "165000\n",
            "166000\n",
            "167000\n",
            "168000\n",
            "169000\n",
            "170000\n",
            "171000\n",
            "172000\n",
            "173000\n",
            "174000\n",
            "175000\n",
            "176000\n",
            "177000\n",
            "178000\n",
            "179000\n",
            "180000\n",
            "181000\n",
            "182000\n",
            "183000\n",
            "184000\n",
            "185000\n",
            "186000\n",
            "187000\n",
            "188000\n",
            "189000\n",
            "190000\n",
            "191000\n",
            "192000\n",
            "193000\n",
            "194000\n",
            "195000\n",
            "196000\n",
            "197000\n",
            "198000\n",
            "199000\n",
            "200000\n",
            "201000\n",
            "202000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cI0sejenUij1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "def generate_dataset(data, folder):\n",
        "    dataset_rgb = np.ndarray([len(data),32,32,3], dtype='float32')\n",
        "    dataset_gray = np.ndarray([len(data), 32, 32, 1], dtype='float32')\n",
        "    labels = np.ones([len(data),6], dtype=int) * 10\n",
        "    for i in np.arange(len(data)):\n",
        "        if (i % 1000 == 0):\n",
        "            print(i)\n",
        "        filename = data[i]['filename']\n",
        "        fullname = os.path.join(folder, filename)\n",
        "        im = cv2.cvtColor(cv2.imread(fullname), cv2.COLOR_BGR2RGB)\n",
        "        boxes = data[i]['boxes']\n",
        "        num_digit = len(boxes)\n",
        "        labels[i,0] = num_digit\n",
        "        top = np.ndarray([num_digit], dtype='float32')\n",
        "        left = np.ndarray([num_digit], dtype='float32')\n",
        "        height = np.ndarray([num_digit], dtype='float32')\n",
        "        width = np.ndarray([num_digit], dtype='float32')  \n",
        "        for j in np.arange(num_digit):\n",
        "            if j < 5: \n",
        "                labels[i,j+1] = boxes[j][0]\n",
        "                if boxes[j][0] == 10: labels[i,j+1] = 0\n",
        "            else:\n",
        "                print('#',i,'image has more than 5 digits.')\n",
        "                continue\n",
        "            top[j] = boxes[j][3]\n",
        "            left[j] = boxes[j][2]\n",
        "            height[j] = boxes[j][1]\n",
        "            width[j] = boxes[j][4]\n",
        "        ha = np.max([0, np.int16(np.min(top))])\n",
        "        wa = np.max([0, np.int16(np.min(left))])\n",
        "        hb = np.int16(np.max(height) + ha)\n",
        "        wb = np.int16(np.sum(width)  + wa)\n",
        "        h3 = (hb - ha) * .3\n",
        "        w3 = (wb - wa) * .3\n",
        "        ha = np.max([0,  np.int16(ha - h3)])\n",
        "        hb = np.min([im.shape[0], np.int16(hb + h3)])\n",
        "        wa = np.max([0,  np.int16(wa - w3)])\n",
        "        wb = np.min([im.shape[1], np.int16(wb + w3)])\n",
        "        im = im[ha:hb, wa:wb, :]\n",
        "        im = cv2.resize(im, (32, 32))\n",
        "        im_gray = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
        "        im_gray = im_gray.reshape((32, 32, 1))\n",
        "        dataset_rgb[i,:,:,:] = im[:,:,:]\n",
        "    return dataset_rgb, dataset_gray, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MGyysR5wU71v",
        "colab_type": "code",
        "outputId": "ebfa80c6-3041-417a-ece7-22c82682fd6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3468
        }
      },
      "cell_type": "code",
      "source": [
        "# train_rgb, train_gray, train_labels = generate_dataset(train_data, 'train')\n",
        "# test_rgb, test_gray, test_labels = generate_dataset(test_data, 'test')\n",
        "extra_rgb, extra_gray, extra_labels = generate_dataset(extra_data, 'extra')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "50000\n",
            "51000\n",
            "52000\n",
            "53000\n",
            "54000\n",
            "55000\n",
            "56000\n",
            "57000\n",
            "58000\n",
            "59000\n",
            "60000\n",
            "61000\n",
            "62000\n",
            "63000\n",
            "64000\n",
            "65000\n",
            "66000\n",
            "67000\n",
            "68000\n",
            "69000\n",
            "70000\n",
            "71000\n",
            "72000\n",
            "73000\n",
            "74000\n",
            "75000\n",
            "76000\n",
            "77000\n",
            "78000\n",
            "79000\n",
            "80000\n",
            "81000\n",
            "82000\n",
            "83000\n",
            "84000\n",
            "85000\n",
            "86000\n",
            "87000\n",
            "88000\n",
            "89000\n",
            "90000\n",
            "91000\n",
            "92000\n",
            "93000\n",
            "94000\n",
            "95000\n",
            "96000\n",
            "97000\n",
            "98000\n",
            "99000\n",
            "100000\n",
            "101000\n",
            "102000\n",
            "103000\n",
            "104000\n",
            "105000\n",
            "106000\n",
            "107000\n",
            "108000\n",
            "109000\n",
            "110000\n",
            "111000\n",
            "112000\n",
            "113000\n",
            "114000\n",
            "115000\n",
            "116000\n",
            "117000\n",
            "118000\n",
            "119000\n",
            "120000\n",
            "121000\n",
            "122000\n",
            "123000\n",
            "124000\n",
            "125000\n",
            "126000\n",
            "127000\n",
            "128000\n",
            "129000\n",
            "130000\n",
            "131000\n",
            "132000\n",
            "133000\n",
            "134000\n",
            "135000\n",
            "136000\n",
            "137000\n",
            "138000\n",
            "139000\n",
            "140000\n",
            "141000\n",
            "142000\n",
            "143000\n",
            "144000\n",
            "145000\n",
            "146000\n",
            "147000\n",
            "148000\n",
            "149000\n",
            "150000\n",
            "151000\n",
            "152000\n",
            "153000\n",
            "154000\n",
            "155000\n",
            "156000\n",
            "157000\n",
            "158000\n",
            "159000\n",
            "160000\n",
            "161000\n",
            "162000\n",
            "163000\n",
            "164000\n",
            "165000\n",
            "166000\n",
            "167000\n",
            "168000\n",
            "169000\n",
            "170000\n",
            "171000\n",
            "172000\n",
            "173000\n",
            "174000\n",
            "175000\n",
            "176000\n",
            "177000\n",
            "178000\n",
            "179000\n",
            "180000\n",
            "181000\n",
            "182000\n",
            "183000\n",
            "184000\n",
            "185000\n",
            "186000\n",
            "187000\n",
            "188000\n",
            "189000\n",
            "190000\n",
            "191000\n",
            "192000\n",
            "193000\n",
            "194000\n",
            "195000\n",
            "196000\n",
            "197000\n",
            "198000\n",
            "199000\n",
            "200000\n",
            "201000\n",
            "202000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jWOn-fwsVC_-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"data\"):\n",
        "  os.mkdir(\"data\")\n",
        "\n",
        "if not os.path.exists(\"data/rgb\"):\n",
        "  os.mkdir(\"data/rgb\")\n",
        "\n",
        "if not os.path.exists(\"data/gray\"):\n",
        "  os.mkdir(\"data/gray\")\n",
        "\n",
        "if not os.path.exists(\"data/labels\"):\n",
        "  os.mkdir(\"data/labels\")\n",
        "\n",
        "# np.save(\"data/rgb/train\", train_rgb)\n",
        "# np.save(\"data/gray/train\", train_gray)\n",
        "# np.save(\"data/labels/train\", train_labels)\n",
        "\n",
        "# np.save(\"data/rgb/test\", test_rgb)\n",
        "# np.save(\"data/gray/test\", test_gray)\n",
        "# np.save(\"data/labels/test\", test_labels)\n",
        "\n",
        "np.save(\"data/rgb/extra\", extra_rgb)\n",
        "np.save(\"data/gray/extra\", extra_gray)\n",
        "np.save(\"data/labels/extra\", extra_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iuk_HcSNgf54",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train_rgb = np.load(\"data/rgb/train.npy\")\n",
        "train_gray = np.load(\"data/gray/train.npy\")\n",
        "train_labels = np.load(\"data/labels/train.npy\")\n",
        "\n",
        "test_rgb = np.load(\"data/rgb/test.npy\")\n",
        "test_gray = np.load(\"data/gray/test.npy\")\n",
        "test_labels = np.load(\"data/labels/test.npy\")\n",
        "\n",
        "extra_rgb = np.load(\"data/rgb/extra.npy\")\n",
        "extra_gray = np.load(\"data/gray/extra.npy\")\n",
        "extra_labels = np.load(\"data/labels/extra.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QzWfT1EYVKV3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "full_gray = np.concatenate([train_gray, extra_gray])\n",
        "full_rgb = np.concatenate([train_rgb, extra_rgb])\n",
        "full_labels = np.concatenate([train_labels, extra_labels])\n",
        "\n",
        "import numpy as np\n",
        "arr_rand = np.random.rand(len(train_labels) + len(extra_labels))\n",
        "split = arr_rand < np.percentile(arr_rand, 75)\n",
        "\n",
        "X_train_gray = full_gray[split]\n",
        "X_valid_gray = full_gray[~split]\n",
        "X_test_gray = test_gray\n",
        "\n",
        "X_train = full_rgb[split]\n",
        "X_valid = full_rgb[~split]\n",
        "X_test = test_rgb\n",
        "\n",
        "y_train = full_labels[split]\n",
        "y_valid = full_labels[~split]\n",
        "y_test = test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p1VB9vYiVQfh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"derived_data\"):\n",
        "  os.mkdir(\"derived_data\")\n",
        "\n",
        "if not os.path.exists(\"derived_data/gray_train_valid_test\"):\n",
        "  os.mkdir(\"derived_data/gray_train_valid_test\")\n",
        "\n",
        "if not os.path.exists(\"derived_data/labels\"):\n",
        "  os.mkdir(\"derived_data/labels\")\n",
        "\n",
        "if not os.path.exists(\"derived_data/rgb_train_valid_test\"):\n",
        "  os.mkdir(\"derived_data/rgb_train_valid_test\")\n",
        "\n",
        "np.save('derived_data/gray_train_valid_test/X_train_gray.npy', X_train_gray)\n",
        "np.save('derived_data/gray_train_valid_test/X_valid_gray.npy', X_valid_gray)\n",
        "np.save('derived_data/gray_train_valid_test/X_test_gray.npy', X_test_gray)\n",
        "\n",
        "np.save('derived_data/labels/y_train.npy', y_train)\n",
        "np.save('derived_data/labels/y_valid.npy', y_valid)\n",
        "np.save('derived_data/labels/y_test.npy', y_test)\n",
        "\n",
        "np.save('derived_data/rgb_train_valid_test/X_train.npy', X_train)\n",
        "np.save('derived_data/rgb_train_valid_test/X_valid.npy', X_valid)\n",
        "np.save('derived_data/rgb_train_valid_test/X_test.npy', X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qePwxIpao18c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = np.load('derived_data/rgb_train_valid_test/X_train.npy')\n",
        "X_valid = np.load('derived_data/rgb_train_valid_test/X_valid.npy')\n",
        "X_test = np.load('derived_data/rgb_train_valid_test/X_test.npy')\n",
        "\n",
        "y_train = np.load('derived_data/labels/y_train.npy')\n",
        "y_valid = np.load('derived_data/labels/y_valid.npy')\n",
        "y_test = np.load('derived_data/labels/y_test.npy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CyqutgYJVTzz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num = len(y_train)\n",
        "reshaped_y_train = [(np.reshape(y_train[:num, 1], (num, 1))).astype('uint8'),\n",
        "                    (np.reshape(y_train[:num, 2], (num, 1))).astype('uint8'),\n",
        "                    (np.reshape(y_train[:num, 3], (num, 1))).astype('uint8'),\n",
        "                    (np.reshape(y_train[:num, 4], (num, 1))).astype('uint8'),\n",
        "                    (np.reshape(y_train[:num, 5], (num, 1))).astype('uint8')]\n",
        "\n",
        "num = len(y_valid)\n",
        "reshaped_y_valid = [(np.reshape(y_valid[:num, 1], (num, 1))).astype('uint8'),\n",
        "                    (np.reshape(y_valid[:num, 2], (num, 1))).astype('uint8'),\n",
        "                    (np.reshape(y_valid[:num, 3], (num, 1))).astype('uint8'),\n",
        "                    (np.reshape(y_valid[:num, 4], (num, 1))).astype('uint8'),\n",
        "                    (np.reshape(y_valid[:num, 5], (num, 1))).astype('uint8')]\n",
        "\n",
        "num = len(y_test)\n",
        "reshaped_y_test = [(np.reshape(y_test[:num, 1], (num, 1))).astype('uint8'),\n",
        "                    (np.reshape(y_test[:num, 2], (num, 1))).astype('uint8'),\n",
        "                    (np.reshape(y_test[:num, 3], (num, 1))).astype('uint8'),\n",
        "                    (np.reshape(y_test[:num, 4], (num, 1))).astype('uint8'),\n",
        "                    (np.reshape(y_test[:num, 5], (num, 1))).astype('uint8')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vOf4G_1WVU6c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rgb_data = {}\n",
        "rgb_data['trainX'] = X_train\n",
        "rgb_data['valdX'] = X_valid\n",
        "rgb_data['testX'] = X_test\n",
        "rgb_data['trainY'] = reshaped_y_train\n",
        "rgb_data['valdY'] = reshaped_y_valid\n",
        "rgb_data['testY'] = reshaped_y_test\n",
        "\n",
        "gray_data = {}\n",
        "gray_data['trainX'] = X_train_gray\n",
        "gray_data['valdX'] = X_valid_gray\n",
        "gray_data['testX'] = X_test_gray\n",
        "gray_data['trainY'] = reshaped_y_train\n",
        "gray_data['valdY'] = reshaped_y_valid\n",
        "gray_data['testY'] = reshaped_y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qujw6c1sVXvs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "\n",
        "def scratchVGG16_Model(X_train, X_valid, X_test, reshaped_y_train, reshaped_y_valid, reshaped_y_test):\n",
        "    \n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "    sess = tf.Session(config = config)\n",
        "    tf.keras.backend.set_session(sess)\n",
        "    \n",
        "    if tf.test.gpu_device_name():\n",
        "      print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "    else:\n",
        "       print(\"Please install GPU version of TF\")\n",
        "    _,row, col,channel = X_train.shape\n",
        "    digLen = 5 # including category 0\n",
        "    numDigits = 11\n",
        "    epochs = 50\n",
        "    batch_size = 64\n",
        "    \n",
        "    vgg16Model = VGG16(include_top = False, weights = None)\n",
        "    vgg16Model.summary()\n",
        "    ptInput = tf.keras.Input(shape = (row,col,channel), name  = 'vgg16Scratch')\n",
        "    vgg16 = vgg16Model(ptInput)\n",
        "\n",
        "    vgg16 = Flatten()(vgg16)\n",
        "    vgg16 = Dense(512, activation='relu')(vgg16)\n",
        "    vgg16 = Dense(512, activation='relu')(vgg16)\n",
        "    vgg16 = Dropout(0.5)(vgg16)\n",
        "    \n",
        "    d1 = Dense(11, activation='softmax')(vgg16)\n",
        "    d2 = Dense(11, activation='softmax')(vgg16)\n",
        "    d3 = Dense(11, activation='softmax')(vgg16)\n",
        "    d4 = Dense(11, activation='softmax')(vgg16)\n",
        "    d5 = Dense(11, activation='softmax')(vgg16)\n",
        "    out = [d1, d2, d3, d4, d5]\n",
        "    \n",
        "    vgg16 = tf.keras.Model(inputs = ptInput, outputs = out)\n",
        "\n",
        "    callback = []\n",
        "    optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "    modName = 'vgg16_scratch'\n",
        "    checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='models/{}/vgg16.classifier.hdf5'.format(modName),\n",
        "                                                   monitor='loss',\n",
        "                                                   save_best_only=True,\n",
        "                                                   verbose=2)\n",
        "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'loss',\n",
        "                                                  factor = 0.1,\n",
        "                                                  verbose = 1,\n",
        "                                                  patience= 3,\n",
        "                                                  cooldown= 0,\n",
        "                                                  min_lr = 0.000001)\n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor= 'val_loss',\n",
        "                                       min_delta=0.00000001,\n",
        "                                       patience=5,\n",
        "                                       verbose=1,\n",
        "                                       mode='auto')\n",
        "    callback.append(es)\n",
        "    callback.append(checkpointer)\n",
        "    callback.append(reduce_lr)\n",
        "    vgg16.summary()\n",
        "\n",
        "    vgg16.compile(loss = 'sparse_categorical_crossentropy',\n",
        "                  optimizer= optim,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    vgg16History = vgg16.fit(x = X_train,\n",
        "                             y = reshaped_y_train,\n",
        "                             batch_size = batch_size,\n",
        "                             epochs=1,\n",
        "                             verbose=1,\n",
        "                             shuffle = True,\n",
        "                             validation_data = (X_valid, reshaped_y_valid),\n",
        "                             callbacks = callback)\n",
        "    pickle_file = 'models/{}/history.pickle'.format(modName)\n",
        "    pickle.dump(vgg16History.history, open(pickle_file, 'wb'))\n",
        "    vgg16.save(\"models/{}/model.h5\".format(modName))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hpzghNkNOE4B",
        "colab_type": "code",
        "outputId": "d7f3a110-c063-4f32-9a43-20ddca59ead2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3318
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.Session(config = config)\n",
        "tf.keras.backend.set_session(sess)\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "  print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "   print(\"Please install GPU version of TF\")\n",
        "_,row, col,channel = X_train.shape\n",
        "digLen = 5 # including category 0\n",
        "numDigits = 11\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "vgg16Model = VGG16(include_top = False, weights = None)\n",
        "vgg16Model.summary()\n",
        "ptInput = tf.keras.Input(shape = (row,col,channel), name  = 'vgg16Scratch')\n",
        "vgg16 = vgg16Model(ptInput)\n",
        "\n",
        "vgg16 = Flatten()(vgg16)\n",
        "vgg16 = Dense(512, activation='relu')(vgg16)\n",
        "vgg16 = Dense(512, activation='relu')(vgg16)\n",
        "vgg16 = Dropout(0.5)(vgg16)\n",
        "\n",
        "d1 = Dense(11, activation='softmax')(vgg16)\n",
        "d2 = Dense(11, activation='softmax')(vgg16)\n",
        "d3 = Dense(11, activation='softmax')(vgg16)\n",
        "d4 = Dense(11, activation='softmax')(vgg16)\n",
        "d5 = Dense(11, activation='softmax')(vgg16)\n",
        "out = [d1, d2, d3, d4, d5]\n",
        "\n",
        "vgg16 = tf.keras.Model(inputs = ptInput, outputs = out)\n",
        "\n",
        "callback = []\n",
        "optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "modName = 'vgg16_scratch'\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='models/{}/vgg16.classifier.hdf5'.format(modName),\n",
        "                                               monitor='loss',\n",
        "                                               save_best_only=True,\n",
        "                                               verbose=2)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'loss',\n",
        "                                              factor = 0.1,\n",
        "                                              verbose = 1,\n",
        "                                              patience= 3,\n",
        "                                              cooldown= 0,\n",
        "                                              min_lr = 0.000001)\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor= 'val_loss',\n",
        "                                   min_delta=0.00000001,\n",
        "                                   patience=5,\n",
        "                                   verbose=1,\n",
        "                                   mode='auto')\n",
        "callback.append(es)\n",
        "callback.append(checkpointer)\n",
        "callback.append(reduce_lr)\n",
        "vgg16.summary()\n",
        "\n",
        "vgg16.compile(loss = 'sparse_categorical_crossentropy',\n",
        "              optimizer= optim,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "vgg16History = vgg16.fit(x = X_train,\n",
        "                         y = reshaped_y_train,\n",
        "                         batch_size = batch_size,\n",
        "                         epochs=epochs,\n",
        "                         verbose=1,\n",
        "                         shuffle = True,\n",
        "                         validation_data = (X_valid, reshaped_y_valid),\n",
        "                         callbacks = callback)\n",
        "pickle_file = 'models/{}/history.pickle'.format(modName)\n",
        "pickle.dump(vgg16History.history, open(pickle_file, 'wb'))\n",
        "vgg16.save(\"models/{}/model.h5\".format(modName))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default GPU Device: /device:GPU:0\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "vgg16Scratch (InputLayer)       (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "vgg16 (Model)                   multiple             14714688    vgg16Scratch[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_13 (Flatten)            (None, 512)          0           vgg16[1][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_91 (Dense)                (None, 512)          262656      flatten_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_92 (Dense)                (None, 512)          262656      dense_91[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 512)          0           dense_92[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_93 (Dense)                (None, 11)           5643        dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_94 (Dense)                (None, 11)           5643        dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_95 (Dense)                (None, 11)           5643        dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_96 (Dense)                (None, 11)           5643        dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_97 (Dense)                (None, 11)           5643        dropout_13[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 15,268,215\n",
            "Trainable params: 15,268,215\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 176816 samples, validate on 58939 samples\n",
            "Epoch 1/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 5.3825 - dense_93_loss: 1.6003 - dense_94_loss: 1.9808 - dense_95_loss: 1.4553 - dense_96_loss: 0.3277 - dense_97_loss: 0.0185 - dense_93_acc: 0.4314 - dense_94_acc: 0.2759 - dense_95_acc: 0.5305 - dense_96_acc: 0.9329 - dense_97_acc: 0.9992\n",
            "Epoch 00001: loss improved from inf to 5.38200, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 165s 934us/sample - loss: 5.3820 - dense_93_loss: 1.6001 - dense_94_loss: 1.9806 - dense_95_loss: 1.4551 - dense_96_loss: 0.3277 - dense_97_loss: 0.0185 - dense_93_acc: 0.4315 - dense_94_acc: 0.2760 - dense_95_acc: 0.5305 - dense_96_acc: 0.9329 - dense_97_acc: 0.9992 - val_loss: 3.3364 - val_dense_93_loss: 0.9488 - val_dense_94_loss: 1.2281 - val_dense_95_loss: 0.9271 - val_dense_96_loss: 0.2253 - val_dense_97_loss: 0.0070 - val_dense_93_acc: 0.6620 - val_dense_94_acc: 0.5467 - val_dense_95_acc: 0.6673 - val_dense_96_acc: 0.9391 - val_dense_97_acc: 0.9993\n",
            "Epoch 2/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 2.3956 - dense_93_loss: 0.6389 - dense_94_loss: 0.8494 - dense_95_loss: 0.6985 - dense_96_loss: 0.2037 - dense_97_loss: 0.0050 - dense_93_acc: 0.7894 - dense_94_acc: 0.7112 - dense_95_acc: 0.7719 - dense_96_acc: 0.9438 - dense_97_acc: 0.9995\n",
            "Epoch 00002: loss improved from 5.38200 to 2.39531, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 153s 863us/sample - loss: 2.3953 - dense_93_loss: 0.6388 - dense_94_loss: 0.8494 - dense_95_loss: 0.6985 - dense_96_loss: 0.2037 - dense_97_loss: 0.0050 - dense_93_acc: 0.7894 - dense_94_acc: 0.7112 - dense_95_acc: 0.7719 - dense_96_acc: 0.9438 - dense_97_acc: 0.9995 - val_loss: 1.6516 - val_dense_93_loss: 0.3899 - val_dense_94_loss: 0.5549 - val_dense_95_loss: 0.5024 - val_dense_96_loss: 0.1980 - val_dense_97_loss: 0.0064 - val_dense_93_acc: 0.8921 - val_dense_94_acc: 0.8350 - val_dense_95_acc: 0.8552 - val_dense_96_acc: 0.9471 - val_dense_97_acc: 0.9993\n",
            "Epoch 3/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 1.4495 - dense_93_loss: 0.3432 - dense_94_loss: 0.4858 - dense_95_loss: 0.4548 - dense_96_loss: 0.1608 - dense_97_loss: 0.0050 - dense_93_acc: 0.9108 - dense_94_acc: 0.8675 - dense_95_acc: 0.8718 - dense_96_acc: 0.9554 - dense_97_acc: 0.9995\n",
            "Epoch 00003: loss improved from 2.39531 to 1.44950, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 152s 859us/sample - loss: 1.4495 - dense_93_loss: 0.3432 - dense_94_loss: 0.4858 - dense_95_loss: 0.4547 - dense_96_loss: 0.1608 - dense_97_loss: 0.0050 - dense_93_acc: 0.9108 - dense_94_acc: 0.8675 - dense_95_acc: 0.8718 - dense_96_acc: 0.9554 - dense_97_acc: 0.9995 - val_loss: 1.3388 - val_dense_93_loss: 0.2892 - val_dense_94_loss: 0.4651 - val_dense_95_loss: 0.4043 - val_dense_96_loss: 0.1736 - val_dense_97_loss: 0.0066 - val_dense_93_acc: 0.9275 - val_dense_94_acc: 0.8761 - val_dense_95_acc: 0.8887 - val_dense_96_acc: 0.9563 - val_dense_97_acc: 0.9993\n",
            "Epoch 4/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 1.2051 - dense_93_loss: 0.2859 - dense_94_loss: 0.3898 - dense_95_loss: 0.3986 - dense_96_loss: 0.1259 - dense_97_loss: 0.0049 - dense_93_acc: 0.9296 - dense_94_acc: 0.9000 - dense_95_acc: 0.8892 - dense_96_acc: 0.9671 - dense_97_acc: 0.9995\n",
            "Epoch 00004: loss improved from 1.44950 to 1.20508, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 152s 860us/sample - loss: 1.2051 - dense_93_loss: 0.2859 - dense_94_loss: 0.3898 - dense_95_loss: 0.3986 - dense_96_loss: 0.1259 - dense_97_loss: 0.0049 - dense_93_acc: 0.9296 - dense_94_acc: 0.9000 - dense_95_acc: 0.8892 - dense_96_acc: 0.9671 - dense_97_acc: 0.9995 - val_loss: 1.1486 - val_dense_93_loss: 0.2591 - val_dense_94_loss: 0.3775 - val_dense_95_loss: 0.3895 - val_dense_96_loss: 0.1138 - val_dense_97_loss: 0.0087 - val_dense_93_acc: 0.9366 - val_dense_94_acc: 0.9075 - val_dense_95_acc: 0.8925 - val_dense_96_acc: 0.9709 - val_dense_97_acc: 0.9993\n",
            "Epoch 5/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 1.0698 - dense_93_loss: 0.2482 - dense_94_loss: 0.3453 - dense_95_loss: 0.3675 - dense_96_loss: 0.1038 - dense_97_loss: 0.0048 - dense_93_acc: 0.9389 - dense_94_acc: 0.9132 - dense_95_acc: 0.8977 - dense_96_acc: 0.9737 - dense_97_acc: 0.9995\n",
            "Epoch 00005: loss improved from 1.20508 to 1.06963, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 152s 862us/sample - loss: 1.0696 - dense_93_loss: 0.2482 - dense_94_loss: 0.3453 - dense_95_loss: 0.3675 - dense_96_loss: 0.1038 - dense_97_loss: 0.0048 - dense_93_acc: 0.9389 - dense_94_acc: 0.9132 - dense_95_acc: 0.8977 - dense_96_acc: 0.9737 - dense_97_acc: 0.9995 - val_loss: 1.0633 - val_dense_93_loss: 0.2389 - val_dense_94_loss: 0.3210 - val_dense_95_loss: 0.3646 - val_dense_96_loss: 0.1304 - val_dense_97_loss: 0.0083 - val_dense_93_acc: 0.9425 - val_dense_94_acc: 0.9206 - val_dense_95_acc: 0.8986 - val_dense_96_acc: 0.9721 - val_dense_97_acc: 0.9993\n",
            "Epoch 6/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.9985 - dense_93_loss: 0.2312 - dense_94_loss: 0.3156 - dense_95_loss: 0.3519 - dense_96_loss: 0.0956 - dense_97_loss: 0.0041 - dense_93_acc: 0.9439 - dense_94_acc: 0.9217 - dense_95_acc: 0.9010 - dense_96_acc: 0.9768 - dense_97_acc: 0.9995\n",
            "Epoch 00006: loss improved from 1.06963 to 0.99844, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 152s 860us/sample - loss: 0.9984 - dense_93_loss: 0.2312 - dense_94_loss: 0.3156 - dense_95_loss: 0.3519 - dense_96_loss: 0.0956 - dense_97_loss: 0.0041 - dense_93_acc: 0.9439 - dense_94_acc: 0.9217 - dense_95_acc: 0.9010 - dense_96_acc: 0.9768 - dense_97_acc: 0.9995 - val_loss: 1.0011 - val_dense_93_loss: 0.2403 - val_dense_94_loss: 0.3210 - val_dense_95_loss: 0.3463 - val_dense_96_loss: 0.0870 - val_dense_97_loss: 0.0066 - val_dense_93_acc: 0.9426 - val_dense_94_acc: 0.9210 - val_dense_95_acc: 0.9018 - val_dense_96_acc: 0.9799 - val_dense_97_acc: 0.9993\n",
            "Epoch 7/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.9391 - dense_93_loss: 0.2188 - dense_94_loss: 0.2916 - dense_95_loss: 0.3376 - dense_96_loss: 0.0868 - dense_97_loss: 0.0043 - dense_93_acc: 0.9478 - dense_94_acc: 0.9288 - dense_95_acc: 0.9043 - dense_96_acc: 0.9792 - dense_97_acc: 0.9995\n",
            "Epoch 00007: loss improved from 0.99844 to 0.93907, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 152s 857us/sample - loss: 0.9391 - dense_93_loss: 0.2188 - dense_94_loss: 0.2917 - dense_95_loss: 0.3375 - dense_96_loss: 0.0868 - dense_97_loss: 0.0043 - dense_93_acc: 0.9478 - dense_94_acc: 0.9288 - dense_95_acc: 0.9043 - dense_96_acc: 0.9792 - dense_97_acc: 0.9995 - val_loss: 0.9520 - val_dense_93_loss: 0.2278 - val_dense_94_loss: 0.3023 - val_dense_95_loss: 0.3290 - val_dense_96_loss: 0.0859 - val_dense_97_loss: 0.0070 - val_dense_93_acc: 0.9443 - val_dense_94_acc: 0.9234 - val_dense_95_acc: 0.9055 - val_dense_96_acc: 0.9812 - val_dense_97_acc: 0.9993\n",
            "Epoch 8/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.8995 - dense_93_loss: 0.2074 - dense_94_loss: 0.2796 - dense_95_loss: 0.3280 - dense_96_loss: 0.0805 - dense_97_loss: 0.0040 - dense_93_acc: 0.9505 - dense_94_acc: 0.9319 - dense_95_acc: 0.9065 - dense_96_acc: 0.9810 - dense_97_acc: 0.9995\n",
            "Epoch 00008: loss improved from 0.93907 to 0.89947, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 152s 858us/sample - loss: 0.8995 - dense_93_loss: 0.2074 - dense_94_loss: 0.2795 - dense_95_loss: 0.3280 - dense_96_loss: 0.0805 - dense_97_loss: 0.0040 - dense_93_acc: 0.9505 - dense_94_acc: 0.9319 - dense_95_acc: 0.9065 - dense_96_acc: 0.9810 - dense_97_acc: 0.9995 - val_loss: 1.0130 - val_dense_93_loss: 0.2322 - val_dense_94_loss: 0.3259 - val_dense_95_loss: 0.3554 - val_dense_96_loss: 0.0930 - val_dense_97_loss: 0.0065 - val_dense_93_acc: 0.9431 - val_dense_94_acc: 0.9192 - val_dense_95_acc: 0.9003 - val_dense_96_acc: 0.9797 - val_dense_97_acc: 0.9993\n",
            "Epoch 9/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.8631 - dense_93_loss: 0.1958 - dense_94_loss: 0.2638 - dense_95_loss: 0.3223 - dense_96_loss: 0.0776 - dense_97_loss: 0.0036 - dense_93_acc: 0.9529 - dense_94_acc: 0.9356 - dense_95_acc: 0.9078 - dense_96_acc: 0.9821 - dense_97_acc: 0.9995\n",
            "Epoch 00009: loss improved from 0.89947 to 0.86312, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 151s 855us/sample - loss: 0.8631 - dense_93_loss: 0.1958 - dense_94_loss: 0.2639 - dense_95_loss: 0.3223 - dense_96_loss: 0.0776 - dense_97_loss: 0.0036 - dense_93_acc: 0.9529 - dense_94_acc: 0.9356 - dense_95_acc: 0.9078 - dense_96_acc: 0.9822 - dense_97_acc: 0.9995 - val_loss: 0.9082 - val_dense_93_loss: 0.2025 - val_dense_94_loss: 0.2724 - val_dense_95_loss: 0.3367 - val_dense_96_loss: 0.0888 - val_dense_97_loss: 0.0078 - val_dense_93_acc: 0.9529 - val_dense_94_acc: 0.9332 - val_dense_95_acc: 0.9056 - val_dense_96_acc: 0.9815 - val_dense_97_acc: 0.9993\n",
            "Epoch 10/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.8604 - dense_93_loss: 0.1962 - dense_94_loss: 0.2630 - dense_95_loss: 0.3213 - dense_96_loss: 0.0760 - dense_97_loss: 0.0039 - dense_93_acc: 0.9534 - dense_94_acc: 0.9367 - dense_95_acc: 0.9088 - dense_96_acc: 0.9826 - dense_97_acc: 0.9995\n",
            "Epoch 00010: loss improved from 0.86312 to 0.86034, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 152s 858us/sample - loss: 0.8603 - dense_93_loss: 0.1962 - dense_94_loss: 0.2630 - dense_95_loss: 0.3213 - dense_96_loss: 0.0760 - dense_97_loss: 0.0039 - dense_93_acc: 0.9534 - dense_94_acc: 0.9367 - dense_95_acc: 0.9089 - dense_96_acc: 0.9826 - dense_97_acc: 0.9995 - val_loss: 0.9142 - val_dense_93_loss: 0.2112 - val_dense_94_loss: 0.2849 - val_dense_95_loss: 0.3264 - val_dense_96_loss: 0.0847 - val_dense_97_loss: 0.0070 - val_dense_93_acc: 0.9523 - val_dense_94_acc: 0.9334 - val_dense_95_acc: 0.9090 - val_dense_96_acc: 0.9827 - val_dense_97_acc: 0.9993\n",
            "Epoch 11/50\n",
            "176704/176816 [============================>.] - ETA: 0s - loss: 0.8586 - dense_93_loss: 0.1995 - dense_94_loss: 0.2635 - dense_95_loss: 0.3172 - dense_96_loss: 0.0745 - dense_97_loss: 0.0038 - dense_93_acc: 0.9524 - dense_94_acc: 0.9369 - dense_95_acc: 0.9092 - dense_96_acc: 0.9829 - dense_97_acc: 0.9995\n",
            "Epoch 00011: loss improved from 0.86034 to 0.85873, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 152s 857us/sample - loss: 0.8587 - dense_93_loss: 0.1995 - dense_94_loss: 0.2636 - dense_95_loss: 0.3172 - dense_96_loss: 0.0746 - dense_97_loss: 0.0038 - dense_93_acc: 0.9524 - dense_94_acc: 0.9369 - dense_95_acc: 0.9092 - dense_96_acc: 0.9829 - dense_97_acc: 0.9995 - val_loss: 0.9445 - val_dense_93_loss: 0.2147 - val_dense_94_loss: 0.2973 - val_dense_95_loss: 0.3383 - val_dense_96_loss: 0.0871 - val_dense_97_loss: 0.0070 - val_dense_93_acc: 0.9489 - val_dense_94_acc: 0.9295 - val_dense_95_acc: 0.9038 - val_dense_96_acc: 0.9813 - val_dense_97_acc: 0.9993\n",
            "Epoch 12/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.8329 - dense_93_loss: 0.1931 - dense_94_loss: 0.2547 - dense_95_loss: 0.3105 - dense_96_loss: 0.0709 - dense_97_loss: 0.0038 - dense_93_acc: 0.9548 - dense_94_acc: 0.9394 - dense_95_acc: 0.9107 - dense_96_acc: 0.9838 - dense_97_acc: 0.9995\n",
            "Epoch 00012: loss improved from 0.85873 to 0.83301, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 152s 857us/sample - loss: 0.8330 - dense_93_loss: 0.1932 - dense_94_loss: 0.2547 - dense_95_loss: 0.3105 - dense_96_loss: 0.0709 - dense_97_loss: 0.0038 - dense_93_acc: 0.9547 - dense_94_acc: 0.9394 - dense_95_acc: 0.9107 - dense_96_acc: 0.9838 - dense_97_acc: 0.9995 - val_loss: 0.9244 - val_dense_93_loss: 0.2084 - val_dense_94_loss: 0.2891 - val_dense_95_loss: 0.3345 - val_dense_96_loss: 0.0857 - val_dense_97_loss: 0.0067 - val_dense_93_acc: 0.9515 - val_dense_94_acc: 0.9315 - val_dense_95_acc: 0.9072 - val_dense_96_acc: 0.9823 - val_dense_97_acc: 0.9993\n",
            "Epoch 13/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.8061 - dense_93_loss: 0.1854 - dense_94_loss: 0.2420 - dense_95_loss: 0.3049 - dense_96_loss: 0.0702 - dense_97_loss: 0.0036 - dense_93_acc: 0.9562 - dense_94_acc: 0.9426 - dense_95_acc: 0.9123 - dense_96_acc: 0.9844 - dense_97_acc: 0.9995\n",
            "Epoch 00013: loss improved from 0.83301 to 0.80623, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 151s 855us/sample - loss: 0.8062 - dense_93_loss: 0.1854 - dense_94_loss: 0.2420 - dense_95_loss: 0.3049 - dense_96_loss: 0.0702 - dense_97_loss: 0.0036 - dense_93_acc: 0.9561 - dense_94_acc: 0.9426 - dense_95_acc: 0.9123 - dense_96_acc: 0.9844 - dense_97_acc: 0.9995 - val_loss: 0.9261 - val_dense_93_loss: 0.2042 - val_dense_94_loss: 0.2886 - val_dense_95_loss: 0.3391 - val_dense_96_loss: 0.0872 - val_dense_97_loss: 0.0071 - val_dense_93_acc: 0.9551 - val_dense_94_acc: 0.9341 - val_dense_95_acc: 0.9088 - val_dense_96_acc: 0.9837 - val_dense_97_acc: 0.9993\n",
            "Epoch 14/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.7975 - dense_93_loss: 0.1834 - dense_94_loss: 0.2383 - dense_95_loss: 0.3017 - dense_96_loss: 0.0704 - dense_97_loss: 0.0036 - dense_93_acc: 0.9575 - dense_94_acc: 0.9434 - dense_95_acc: 0.9135 - dense_96_acc: 0.9843 - dense_97_acc: 0.9995\n",
            "Epoch 00014: loss improved from 0.80623 to 0.79746, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 152s 859us/sample - loss: 0.7975 - dense_93_loss: 0.1834 - dense_94_loss: 0.2384 - dense_95_loss: 0.3017 - dense_96_loss: 0.0705 - dense_97_loss: 0.0036 - dense_93_acc: 0.9575 - dense_94_acc: 0.9434 - dense_95_acc: 0.9135 - dense_96_acc: 0.9843 - dense_97_acc: 0.9995 - val_loss: 0.9081 - val_dense_93_loss: 0.2123 - val_dense_94_loss: 0.2785 - val_dense_95_loss: 0.3265 - val_dense_96_loss: 0.0841 - val_dense_97_loss: 0.0067 - val_dense_93_acc: 0.9531 - val_dense_94_acc: 0.9365 - val_dense_95_acc: 0.9099 - val_dense_96_acc: 0.9827 - val_dense_97_acc: 0.9993\n",
            "Epoch 15/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.7876 - dense_93_loss: 0.1790 - dense_94_loss: 0.2384 - dense_95_loss: 0.2967 - dense_96_loss: 0.0697 - dense_97_loss: 0.0038 - dense_93_acc: 0.9583 - dense_94_acc: 0.9439 - dense_95_acc: 0.9142 - dense_96_acc: 0.9847 - dense_97_acc: 0.9995\n",
            "Epoch 00015: loss improved from 0.79746 to 0.78756, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 151s 855us/sample - loss: 0.7876 - dense_93_loss: 0.1790 - dense_94_loss: 0.2384 - dense_95_loss: 0.2967 - dense_96_loss: 0.0697 - dense_97_loss: 0.0038 - dense_93_acc: 0.9583 - dense_94_acc: 0.9439 - dense_95_acc: 0.9142 - dense_96_acc: 0.9847 - dense_97_acc: 0.9995 - val_loss: 1.0126 - val_dense_93_loss: 0.2436 - val_dense_94_loss: 0.3193 - val_dense_95_loss: 0.3479 - val_dense_96_loss: 0.0956 - val_dense_97_loss: 0.0061 - val_dense_93_acc: 0.9420 - val_dense_94_acc: 0.9264 - val_dense_95_acc: 0.9037 - val_dense_96_acc: 0.9799 - val_dense_97_acc: 0.9993\n",
            "Epoch 16/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.7890 - dense_93_loss: 0.1805 - dense_94_loss: 0.2388 - dense_95_loss: 0.2964 - dense_96_loss: 0.0696 - dense_97_loss: 0.0038 - dense_93_acc: 0.9584 - dense_94_acc: 0.9438 - dense_95_acc: 0.9143 - dense_96_acc: 0.9848 - dense_97_acc: 0.9995\n",
            "Epoch 00016: loss did not improve from 0.78756\n",
            "176816/176816 [==============================] - 150s 847us/sample - loss: 0.7890 - dense_93_loss: 0.1805 - dense_94_loss: 0.2388 - dense_95_loss: 0.2964 - dense_96_loss: 0.0696 - dense_97_loss: 0.0038 - dense_93_acc: 0.9584 - dense_94_acc: 0.9438 - dense_95_acc: 0.9143 - dense_96_acc: 0.9848 - dense_97_acc: 0.9995 - val_loss: 0.8941 - val_dense_93_loss: 0.2085 - val_dense_94_loss: 0.2717 - val_dense_95_loss: 0.3203 - val_dense_96_loss: 0.0869 - val_dense_97_loss: 0.0067 - val_dense_93_acc: 0.9520 - val_dense_94_acc: 0.9359 - val_dense_95_acc: 0.9103 - val_dense_96_acc: 0.9840 - val_dense_97_acc: 0.9993\n",
            "Epoch 17/50\n",
            "176704/176816 [============================>.] - ETA: 0s - loss: 0.7596 - dense_93_loss: 0.1736 - dense_94_loss: 0.2284 - dense_95_loss: 0.2854 - dense_96_loss: 0.0686 - dense_97_loss: 0.0036 - dense_93_acc: 0.9594 - dense_94_acc: 0.9465 - dense_95_acc: 0.9166 - dense_96_acc: 0.9849 - dense_97_acc: 0.9995\n",
            "Epoch 00017: loss improved from 0.78756 to 0.75950, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 151s 855us/sample - loss: 0.7595 - dense_93_loss: 0.1736 - dense_94_loss: 0.2284 - dense_95_loss: 0.2853 - dense_96_loss: 0.0686 - dense_97_loss: 0.0036 - dense_93_acc: 0.9594 - dense_94_acc: 0.9465 - dense_95_acc: 0.9166 - dense_96_acc: 0.9849 - dense_97_acc: 0.9995 - val_loss: 0.9490 - val_dense_93_loss: 0.2385 - val_dense_94_loss: 0.2909 - val_dense_95_loss: 0.3264 - val_dense_96_loss: 0.0857 - val_dense_97_loss: 0.0075 - val_dense_93_acc: 0.9457 - val_dense_94_acc: 0.9318 - val_dense_95_acc: 0.9070 - val_dense_96_acc: 0.9814 - val_dense_97_acc: 0.9993\n",
            "Epoch 18/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.7781 - dense_93_loss: 0.1815 - dense_94_loss: 0.2337 - dense_95_loss: 0.2894 - dense_96_loss: 0.0696 - dense_97_loss: 0.0038 - dense_93_acc: 0.9572 - dense_94_acc: 0.9455 - dense_95_acc: 0.9154 - dense_96_acc: 0.9846 - dense_97_acc: 0.9995\n",
            "Epoch 00018: loss did not improve from 0.75950\n",
            "176816/176816 [==============================] - 150s 850us/sample - loss: 0.7779 - dense_93_loss: 0.1815 - dense_94_loss: 0.2337 - dense_95_loss: 0.2894 - dense_96_loss: 0.0696 - dense_97_loss: 0.0038 - dense_93_acc: 0.9572 - dense_94_acc: 0.9455 - dense_95_acc: 0.9154 - dense_96_acc: 0.9846 - dense_97_acc: 0.9995 - val_loss: 0.9128 - val_dense_93_loss: 0.2276 - val_dense_94_loss: 0.2696 - val_dense_95_loss: 0.3227 - val_dense_96_loss: 0.0855 - val_dense_97_loss: 0.0073 - val_dense_93_acc: 0.9507 - val_dense_94_acc: 0.9409 - val_dense_95_acc: 0.9113 - val_dense_96_acc: 0.9839 - val_dense_97_acc: 0.9993\n",
            "Epoch 19/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.7860 - dense_93_loss: 0.1836 - dense_94_loss: 0.2395 - dense_95_loss: 0.2905 - dense_96_loss: 0.0689 - dense_97_loss: 0.0035 - dense_93_acc: 0.9564 - dense_94_acc: 0.9436 - dense_95_acc: 0.9151 - dense_96_acc: 0.9849 - dense_97_acc: 0.9995\n",
            "Epoch 00019: loss did not improve from 0.75950\n",
            "176816/176816 [==============================] - 150s 851us/sample - loss: 0.7861 - dense_93_loss: 0.1835 - dense_94_loss: 0.2395 - dense_95_loss: 0.2906 - dense_96_loss: 0.0689 - dense_97_loss: 0.0035 - dense_93_acc: 0.9564 - dense_94_acc: 0.9436 - dense_95_acc: 0.9151 - dense_96_acc: 0.9849 - dense_97_acc: 0.9995 - val_loss: 0.8867 - val_dense_93_loss: 0.2089 - val_dense_94_loss: 0.2735 - val_dense_95_loss: 0.3175 - val_dense_96_loss: 0.0798 - val_dense_97_loss: 0.0070 - val_dense_93_acc: 0.9522 - val_dense_94_acc: 0.9359 - val_dense_95_acc: 0.9109 - val_dense_96_acc: 0.9833 - val_dense_97_acc: 0.9993\n",
            "Epoch 20/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.7490 - dense_93_loss: 0.1754 - dense_94_loss: 0.2286 - dense_95_loss: 0.2787 - dense_96_loss: 0.0627 - dense_97_loss: 0.0036 - dense_93_acc: 0.9593 - dense_94_acc: 0.9469 - dense_95_acc: 0.9178 - dense_96_acc: 0.9865 - dense_97_acc: 0.9995\n",
            "Epoch 00020: loss improved from 0.75950 to 0.74909, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 151s 855us/sample - loss: 0.7491 - dense_93_loss: 0.1753 - dense_94_loss: 0.2287 - dense_95_loss: 0.2787 - dense_96_loss: 0.0628 - dense_97_loss: 0.0036 - dense_93_acc: 0.9593 - dense_94_acc: 0.9469 - dense_95_acc: 0.9178 - dense_96_acc: 0.9865 - dense_97_acc: 0.9995 - val_loss: 0.9354 - val_dense_93_loss: 0.2160 - val_dense_94_loss: 0.2949 - val_dense_95_loss: 0.3300 - val_dense_96_loss: 0.0872 - val_dense_97_loss: 0.0073 - val_dense_93_acc: 0.9527 - val_dense_94_acc: 0.9364 - val_dense_95_acc: 0.9105 - val_dense_96_acc: 0.9835 - val_dense_97_acc: 0.9993\n",
            "Epoch 21/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.7673 - dense_93_loss: 0.1791 - dense_94_loss: 0.2307 - dense_95_loss: 0.2857 - dense_96_loss: 0.0678 - dense_97_loss: 0.0040 - dense_93_acc: 0.9584 - dense_94_acc: 0.9463 - dense_95_acc: 0.9170 - dense_96_acc: 0.9854 - dense_97_acc: 0.9995\n",
            "Epoch 00021: loss did not improve from 0.74909\n",
            "176816/176816 [==============================] - 153s 863us/sample - loss: 0.7672 - dense_93_loss: 0.1791 - dense_94_loss: 0.2306 - dense_95_loss: 0.2857 - dense_96_loss: 0.0678 - dense_97_loss: 0.0040 - dense_93_acc: 0.9584 - dense_94_acc: 0.9463 - dense_95_acc: 0.9170 - dense_96_acc: 0.9854 - dense_97_acc: 0.9995 - val_loss: 0.9055 - val_dense_93_loss: 0.2078 - val_dense_94_loss: 0.2826 - val_dense_95_loss: 0.3196 - val_dense_96_loss: 0.0887 - val_dense_97_loss: 0.0068 - val_dense_93_acc: 0.9510 - val_dense_94_acc: 0.9329 - val_dense_95_acc: 0.9118 - val_dense_96_acc: 0.9831 - val_dense_97_acc: 0.9993\n",
            "Epoch 22/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.7481 - dense_93_loss: 0.1726 - dense_94_loss: 0.2253 - dense_95_loss: 0.2802 - dense_96_loss: 0.0661 - dense_97_loss: 0.0039 - dense_93_acc: 0.9604 - dense_94_acc: 0.9475 - dense_95_acc: 0.9180 - dense_96_acc: 0.9856 - dense_97_acc: 0.9995\n",
            "Epoch 00022: loss improved from 0.74909 to 0.74810, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 152s 862us/sample - loss: 0.7481 - dense_93_loss: 0.1726 - dense_94_loss: 0.2253 - dense_95_loss: 0.2801 - dense_96_loss: 0.0661 - dense_97_loss: 0.0039 - dense_93_acc: 0.9604 - dense_94_acc: 0.9475 - dense_95_acc: 0.9180 - dense_96_acc: 0.9856 - dense_97_acc: 0.9995 - val_loss: 0.9467 - val_dense_93_loss: 0.2176 - val_dense_94_loss: 0.2956 - val_dense_95_loss: 0.3382 - val_dense_96_loss: 0.0894 - val_dense_97_loss: 0.0059 - val_dense_93_acc: 0.9491 - val_dense_94_acc: 0.9316 - val_dense_95_acc: 0.9038 - val_dense_96_acc: 0.9795 - val_dense_97_acc: 0.9993\n",
            "Epoch 23/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.7377 - dense_93_loss: 0.1685 - dense_94_loss: 0.2244 - dense_95_loss: 0.2777 - dense_96_loss: 0.0634 - dense_97_loss: 0.0038 - dense_93_acc: 0.9612 - dense_94_acc: 0.9483 - dense_95_acc: 0.9183 - dense_96_acc: 0.9863 - dense_97_acc: 0.9995\n",
            "Epoch 00023: loss improved from 0.74810 to 0.73772, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 153s 868us/sample - loss: 0.7377 - dense_93_loss: 0.1685 - dense_94_loss: 0.2244 - dense_95_loss: 0.2776 - dense_96_loss: 0.0634 - dense_97_loss: 0.0038 - dense_93_acc: 0.9612 - dense_94_acc: 0.9483 - dense_95_acc: 0.9184 - dense_96_acc: 0.9863 - dense_97_acc: 0.9995 - val_loss: 0.8955 - val_dense_93_loss: 0.2104 - val_dense_94_loss: 0.2782 - val_dense_95_loss: 0.3170 - val_dense_96_loss: 0.0837 - val_dense_97_loss: 0.0064 - val_dense_93_acc: 0.9528 - val_dense_94_acc: 0.9352 - val_dense_95_acc: 0.9117 - val_dense_96_acc: 0.9840 - val_dense_97_acc: 0.9993\n",
            "Epoch 24/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.7132 - dense_93_loss: 0.1647 - dense_94_loss: 0.2109 - dense_95_loss: 0.2737 - dense_96_loss: 0.0604 - dense_97_loss: 0.0035 - dense_93_acc: 0.9628 - dense_94_acc: 0.9514 - dense_95_acc: 0.9192 - dense_96_acc: 0.9871 - dense_97_acc: 0.9995\n",
            "Epoch 00024: loss improved from 0.73772 to 0.71311, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 153s 866us/sample - loss: 0.7131 - dense_93_loss: 0.1647 - dense_94_loss: 0.2108 - dense_95_loss: 0.2737 - dense_96_loss: 0.0604 - dense_97_loss: 0.0035 - dense_93_acc: 0.9628 - dense_94_acc: 0.9514 - dense_95_acc: 0.9192 - dense_96_acc: 0.9871 - dense_97_acc: 0.9995 - val_loss: 0.8065 - val_dense_93_loss: 0.1855 - val_dense_94_loss: 0.2462 - val_dense_95_loss: 0.2926 - val_dense_96_loss: 0.0752 - val_dense_97_loss: 0.0070 - val_dense_93_acc: 0.9590 - val_dense_94_acc: 0.9444 - val_dense_95_acc: 0.9165 - val_dense_96_acc: 0.9845 - val_dense_97_acc: 0.9993\n",
            "Epoch 25/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.7221 - dense_93_loss: 0.1674 - dense_94_loss: 0.2162 - dense_95_loss: 0.2727 - dense_96_loss: 0.0621 - dense_97_loss: 0.0036 - dense_93_acc: 0.9611 - dense_94_acc: 0.9503 - dense_95_acc: 0.9194 - dense_96_acc: 0.9870 - dense_97_acc: 0.9995\n",
            "Epoch 00025: loss did not improve from 0.71311\n",
            "176816/176816 [==============================] - 152s 861us/sample - loss: 0.7221 - dense_93_loss: 0.1675 - dense_94_loss: 0.2162 - dense_95_loss: 0.2727 - dense_96_loss: 0.0621 - dense_97_loss: 0.0036 - dense_93_acc: 0.9611 - dense_94_acc: 0.9503 - dense_95_acc: 0.9194 - dense_96_acc: 0.9870 - dense_97_acc: 0.9995 - val_loss: 0.9153 - val_dense_93_loss: 0.2165 - val_dense_94_loss: 0.2963 - val_dense_95_loss: 0.3157 - val_dense_96_loss: 0.0796 - val_dense_97_loss: 0.0072 - val_dense_93_acc: 0.9527 - val_dense_94_acc: 0.9347 - val_dense_95_acc: 0.9127 - val_dense_96_acc: 0.9839 - val_dense_97_acc: 0.9993\n",
            "Epoch 26/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.7390 - dense_93_loss: 0.1735 - dense_94_loss: 0.2215 - dense_95_loss: 0.2750 - dense_96_loss: 0.0655 - dense_97_loss: 0.0036 - dense_93_acc: 0.9600 - dense_94_acc: 0.9482 - dense_95_acc: 0.9193 - dense_96_acc: 0.9858 - dense_97_acc: 0.9995\n",
            "Epoch 00026: loss did not improve from 0.71311\n",
            "176816/176816 [==============================] - 152s 857us/sample - loss: 0.7391 - dense_93_loss: 0.1735 - dense_94_loss: 0.2216 - dense_95_loss: 0.2750 - dense_96_loss: 0.0655 - dense_97_loss: 0.0036 - dense_93_acc: 0.9599 - dense_94_acc: 0.9482 - dense_95_acc: 0.9193 - dense_96_acc: 0.9858 - dense_97_acc: 0.9995 - val_loss: 1.0390 - val_dense_93_loss: 0.2488 - val_dense_94_loss: 0.3378 - val_dense_95_loss: 0.3497 - val_dense_96_loss: 0.0951 - val_dense_97_loss: 0.0076 - val_dense_93_acc: 0.9399 - val_dense_94_acc: 0.9200 - val_dense_95_acc: 0.9041 - val_dense_96_acc: 0.9809 - val_dense_97_acc: 0.9993\n",
            "Epoch 27/50\n",
            "176704/176816 [============================>.] - ETA: 0s - loss: 0.7069 - dense_93_loss: 0.1612 - dense_94_loss: 0.2112 - dense_95_loss: 0.2683 - dense_96_loss: 0.0622 - dense_97_loss: 0.0039 - dense_93_acc: 0.9629 - dense_94_acc: 0.9509 - dense_95_acc: 0.9206 - dense_96_acc: 0.9865 - dense_97_acc: 0.9995\n",
            "Epoch 00027: loss improved from 0.71311 to 0.70689, saving model to models/vgg16_scratch/vgg16.classifier.hdf5\n",
            "176816/176816 [==============================] - 153s 867us/sample - loss: 0.7069 - dense_93_loss: 0.1613 - dense_94_loss: 0.2112 - dense_95_loss: 0.2683 - dense_96_loss: 0.0622 - dense_97_loss: 0.0039 - dense_93_acc: 0.9629 - dense_94_acc: 0.9509 - dense_95_acc: 0.9206 - dense_96_acc: 0.9865 - dense_97_acc: 0.9995 - val_loss: 0.8670 - val_dense_93_loss: 0.2031 - val_dense_94_loss: 0.2647 - val_dense_95_loss: 0.3089 - val_dense_96_loss: 0.0833 - val_dense_97_loss: 0.0071 - val_dense_93_acc: 0.9554 - val_dense_94_acc: 0.9405 - val_dense_95_acc: 0.9107 - val_dense_96_acc: 0.9827 - val_dense_97_acc: 0.9993\n",
            "Epoch 28/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.7187 - dense_93_loss: 0.1640 - dense_94_loss: 0.2165 - dense_95_loss: 0.2704 - dense_96_loss: 0.0640 - dense_97_loss: 0.0037 - dense_93_acc: 0.9626 - dense_94_acc: 0.9502 - dense_95_acc: 0.9208 - dense_96_acc: 0.9868 - dense_97_acc: 0.9995\n",
            "Epoch 00028: loss did not improve from 0.70689\n",
            "176816/176816 [==============================] - 152s 862us/sample - loss: 0.7188 - dense_93_loss: 0.1640 - dense_94_loss: 0.2165 - dense_95_loss: 0.2705 - dense_96_loss: 0.0641 - dense_97_loss: 0.0037 - dense_93_acc: 0.9626 - dense_94_acc: 0.9502 - dense_95_acc: 0.9208 - dense_96_acc: 0.9868 - dense_97_acc: 0.9995 - val_loss: 0.9243 - val_dense_93_loss: 0.2105 - val_dense_94_loss: 0.3000 - val_dense_95_loss: 0.3201 - val_dense_96_loss: 0.0862 - val_dense_97_loss: 0.0075 - val_dense_93_acc: 0.9537 - val_dense_94_acc: 0.9344 - val_dense_95_acc: 0.9113 - val_dense_96_acc: 0.9836 - val_dense_97_acc: 0.9993\n",
            "Epoch 29/50\n",
            "176704/176816 [============================>.] - ETA: 0s - loss: 0.7170 - dense_93_loss: 0.1645 - dense_94_loss: 0.2145 - dense_95_loss: 0.2711 - dense_96_loss: 0.0632 - dense_97_loss: 0.0037 - dense_93_acc: 0.9625 - dense_94_acc: 0.9506 - dense_95_acc: 0.9204 - dense_96_acc: 0.9868 - dense_97_acc: 0.9995\n",
            "Epoch 00029: loss did not improve from 0.70689\n",
            "176816/176816 [==============================] - 153s 864us/sample - loss: 0.7168 - dense_93_loss: 0.1645 - dense_94_loss: 0.2144 - dense_95_loss: 0.2710 - dense_96_loss: 0.0632 - dense_97_loss: 0.0037 - dense_93_acc: 0.9626 - dense_94_acc: 0.9506 - dense_95_acc: 0.9204 - dense_96_acc: 0.9869 - dense_97_acc: 0.9995 - val_loss: 0.8580 - val_dense_93_loss: 0.2051 - val_dense_94_loss: 0.2716 - val_dense_95_loss: 0.2998 - val_dense_96_loss: 0.0750 - val_dense_97_loss: 0.0065 - val_dense_93_acc: 0.9546 - val_dense_94_acc: 0.9382 - val_dense_95_acc: 0.9121 - val_dense_96_acc: 0.9836 - val_dense_97_acc: 0.9993\n",
            "Epoch 00029: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Lzj4aQ_i5TU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg16 = tf.keras.models.load_model(\"models/vgg16_scratch/model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZTWemBVZjQnJ",
        "colab_type": "code",
        "outputId": "d0f3b605-314f-4fc1-c88b-0b563b4bc4a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "vgg16.to_json()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"class_name\": \"Model\", \"config\": {\"name\": \"model_13\", \"layers\": [{\"name\": \"vgg16Scratch\", \"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 32, 32, 3], \"dtype\": \"float32\", \"sparse\": false, \"name\": \"vgg16Scratch\"}, \"inbound_nodes\": []}, {\"name\": \"vgg16\", \"class_name\": \"Model\", \"config\": {\"name\": \"vgg16\", \"layers\": [{\"name\": \"input_14\", \"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, null, null, 3], \"dtype\": \"float32\", \"sparse\": false, \"name\": \"input_14\"}, \"inbound_nodes\": []}, {\"name\": \"block1_conv1\", \"class_name\": \"Conv2D\", \"config\": {\"name\": \"block1_conv1\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 64, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"input_14\", 0, 0, {}]]]}, {\"name\": \"block1_conv2\", \"class_name\": \"Conv2D\", \"config\": {\"name\": \"block1_conv2\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 64, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"block1_conv1\", 0, 0, {}]]]}, {\"name\": \"block1_pool\", \"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"block1_pool\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2, 2], \"padding\": \"valid\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}, \"inbound_nodes\": [[[\"block1_conv2\", 0, 0, {}]]]}, {\"name\": \"block2_conv1\", \"class_name\": \"Conv2D\", \"config\": {\"name\": \"block2_conv1\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 128, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"block1_pool\", 0, 0, {}]]]}, {\"name\": \"block2_conv2\", \"class_name\": \"Conv2D\", \"config\": {\"name\": \"block2_conv2\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 128, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"block2_conv1\", 0, 0, {}]]]}, {\"name\": \"block2_pool\", \"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"block2_pool\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2, 2], \"padding\": \"valid\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}, \"inbound_nodes\": [[[\"block2_conv2\", 0, 0, {}]]]}, {\"name\": \"block3_conv1\", \"class_name\": \"Conv2D\", \"config\": {\"name\": \"block3_conv1\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 256, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"block2_pool\", 0, 0, {}]]]}, {\"name\": \"block3_conv2\", \"class_name\": \"Conv2D\", \"config\": {\"name\": \"block3_conv2\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 256, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"block3_conv1\", 0, 0, {}]]]}, {\"name\": \"block3_conv3\", \"class_name\": \"Conv2D\", \"config\": {\"name\": \"block3_conv3\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 256, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"block3_conv2\", 0, 0, {}]]]}, {\"name\": \"block3_pool\", \"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"block3_pool\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2, 2], \"padding\": \"valid\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}, \"inbound_nodes\": [[[\"block3_conv3\", 0, 0, {}]]]}, {\"name\": \"block4_conv1\", \"class_name\": \"Conv2D\", \"config\": {\"name\": \"block4_conv1\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 512, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"block3_pool\", 0, 0, {}]]]}, {\"name\": \"block4_conv2\", \"class_name\": \"Conv2D\", \"config\": {\"name\": \"block4_conv2\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 512, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"block4_conv1\", 0, 0, {}]]]}, {\"name\": \"block4_conv3\", \"class_name\": \"Conv2D\", \"config\": {\"name\": \"block4_conv3\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 512, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"block4_conv2\", 0, 0, {}]]]}, {\"name\": \"block4_pool\", \"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"block4_pool\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2, 2], \"padding\": \"valid\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}, \"inbound_nodes\": [[[\"block4_conv3\", 0, 0, {}]]]}, {\"name\": \"block5_conv1\", \"class_name\": \"Conv2D\", \"config\": {\"name\": \"block5_conv1\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 512, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"block4_pool\", 0, 0, {}]]]}, {\"name\": \"block5_conv2\", \"class_name\": \"Conv2D\", \"config\": {\"name\": \"block5_conv2\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 512, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"block5_conv1\", 0, 0, {}]]]}, {\"name\": \"block5_conv3\", \"class_name\": \"Conv2D\", \"config\": {\"name\": \"block5_conv3\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 512, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"block5_conv2\", 0, 0, {}]]]}, {\"name\": \"block5_pool\", \"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"block5_pool\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2, 2], \"padding\": \"valid\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}, \"inbound_nodes\": [[[\"block5_conv3\", 0, 0, {}]]]}], \"input_layers\": [[\"input_14\", 0, 0]], \"output_layers\": [[\"block5_pool\", 0, 0]]}, \"inbound_nodes\": [[[\"vgg16Scratch\", 0, 0, {}]]]}, {\"name\": \"flatten_13\", \"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten_13\", \"trainable\": true, \"dtype\": \"float32\", \"data_format\": \"channels_last\"}, \"inbound_nodes\": [[[\"vgg16\", 1, 0, {}]]]}, {\"name\": \"dense_91\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_91\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 512, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"flatten_13\", 0, 0, {}]]]}, {\"name\": \"dense_92\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_92\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 512, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"dense_91\", 0, 0, {}]]]}, {\"name\": \"dropout_13\", \"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_13\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.5, \"noise_shape\": null, \"seed\": null}, \"inbound_nodes\": [[[\"dense_92\", 0, 0, {}]]]}, {\"name\": \"dense_93\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_93\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 11, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"dropout_13\", 0, 0, {}]]]}, {\"name\": \"dense_94\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_94\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 11, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"dropout_13\", 0, 0, {}]]]}, {\"name\": \"dense_95\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_95\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 11, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"dropout_13\", 0, 0, {}]]]}, {\"name\": \"dense_96\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_96\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 11, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"dropout_13\", 0, 0, {}]]]}, {\"name\": \"dense_97\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_97\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 11, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"dropout_13\", 0, 0, {}]]]}], \"input_layers\": [[\"vgg16Scratch\", 0, 0]], \"output_layers\": [[\"dense_93\", 0, 0], [\"dense_94\", 0, 0], [\"dense_95\", 0, 0], [\"dense_96\", 0, 0], [\"dense_97\", 0, 0]]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "nQzyb9XTjS2E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('models/vgg16_scratch/history.pickle', \"rb\") as f:\n",
        "  data = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-kAfIDTCjh3Q",
        "colab_type": "code",
        "outputId": "2da7747d-3583-425d-9d10-fab51e2e2c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11356
        }
      },
      "cell_type": "code",
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dense_93_acc': [0.43149376,\n",
              "  0.7894252,\n",
              "  0.91079426,\n",
              "  0.9295822,\n",
              "  0.9389252,\n",
              "  0.9439304,\n",
              "  0.9478102,\n",
              "  0.9505192,\n",
              "  0.9529228,\n",
              "  0.95335263,\n",
              "  0.95243645,\n",
              "  0.9547439,\n",
              "  0.9561409,\n",
              "  0.95754343,\n",
              "  0.95827866,\n",
              "  0.9583861,\n",
              "  0.9593702,\n",
              "  0.95724934,\n",
              "  0.956418,\n",
              "  0.95927405,\n",
              "  0.9584257,\n",
              "  0.9603825,\n",
              "  0.96116865,\n",
              "  0.9627749,\n",
              "  0.96111214,\n",
              "  0.9599301,\n",
              "  0.9628767,\n",
              "  0.96263915,\n",
              "  0.9625543],\n",
              " 'dense_93_loss': [1.6001005,\n",
              "  0.63884205,\n",
              "  0.3432035,\n",
              "  0.2858938,\n",
              "  0.2482164,\n",
              "  0.23120044,\n",
              "  0.21880156,\n",
              "  0.20738517,\n",
              "  0.19578572,\n",
              "  0.196203,\n",
              "  0.19945613,\n",
              "  0.19315474,\n",
              "  0.18544273,\n",
              "  0.18337029,\n",
              "  0.17896126,\n",
              "  0.18048541,\n",
              "  0.17360368,\n",
              "  0.18148269,\n",
              "  0.18352747,\n",
              "  0.17532897,\n",
              "  0.1791029,\n",
              "  0.17263381,\n",
              "  0.1684972,\n",
              "  0.16472635,\n",
              "  0.16747439,\n",
              "  0.17354739,\n",
              "  0.1612758,\n",
              "  0.16401517,\n",
              "  0.16448031],\n",
              " 'dense_94_acc': [0.27597615,\n",
              "  0.7112083,\n",
              "  0.86746675,\n",
              "  0.89996946,\n",
              "  0.91315264,\n",
              "  0.92166436,\n",
              "  0.92881864,\n",
              "  0.93194056,\n",
              "  0.93562233,\n",
              "  0.9366573,\n",
              "  0.9369005,\n",
              "  0.93942857,\n",
              "  0.9425504,\n",
              "  0.94341576,\n",
              "  0.9438739,\n",
              "  0.943806,\n",
              "  0.9464868,\n",
              "  0.94548005,\n",
              "  0.9436137,\n",
              "  0.9469335,\n",
              "  0.9463001,\n",
              "  0.9474991,\n",
              "  0.9482513,\n",
              "  0.9514184,\n",
              "  0.9502647,\n",
              "  0.94822866,\n",
              "  0.9508981,\n",
              "  0.9501572,\n",
              "  0.950621],\n",
              " 'dense_94_loss': [1.9806011,\n",
              "  0.84935045,\n",
              "  0.48580453,\n",
              "  0.389844,\n",
              "  0.34531197,\n",
              "  0.31560755,\n",
              "  0.29168344,\n",
              "  0.2795405,\n",
              "  0.2638735,\n",
              "  0.26295072,\n",
              "  0.26360372,\n",
              "  0.25467578,\n",
              "  0.24202073,\n",
              "  0.23836197,\n",
              "  0.23838036,\n",
              "  0.23880565,\n",
              "  0.22836244,\n",
              "  0.23366083,\n",
              "  0.23953927,\n",
              "  0.22865306,\n",
              "  0.23063636,\n",
              "  0.22534253,\n",
              "  0.22442012,\n",
              "  0.21083862,\n",
              "  0.21619758,\n",
              "  0.22156017,\n",
              "  0.21121615,\n",
              "  0.2165221,\n",
              "  0.2144263],\n",
              " 'dense_95_acc': [0.5305063,\n",
              "  0.7719437,\n",
              "  0.87184983,\n",
              "  0.8892012,\n",
              "  0.897679,\n",
              "  0.9010214,\n",
              "  0.90431297,\n",
              "  0.90649605,\n",
              "  0.9078307,\n",
              "  0.9088657,\n",
              "  0.90921634,\n",
              "  0.9106981,\n",
              "  0.91230434,\n",
              "  0.9134694,\n",
              "  0.91415936,\n",
              "  0.9142951,\n",
              "  0.9165969,\n",
              "  0.9154036,\n",
              "  0.9151152,\n",
              "  0.9177846,\n",
              "  0.9169871,\n",
              "  0.91802776,\n",
              "  0.9183558,\n",
              "  0.9192211,\n",
              "  0.9193795,\n",
              "  0.9193116,\n",
              "  0.92064065,\n",
              "  0.9207877,\n",
              "  0.92038614],\n",
              " 'dense_95_loss': [1.4551241,\n",
              "  0.6984752,\n",
              "  0.45467666,\n",
              "  0.39857054,\n",
              "  0.36747336,\n",
              "  0.3518925,\n",
              "  0.3375152,\n",
              "  0.32800257,\n",
              "  0.3222556,\n",
              "  0.32126853,\n",
              "  0.3172132,\n",
              "  0.31049496,\n",
              "  0.3049262,\n",
              "  0.30166164,\n",
              "  0.29672495,\n",
              "  0.2963653,\n",
              "  0.28533182,\n",
              "  0.28937644,\n",
              "  0.29062176,\n",
              "  0.27873132,\n",
              "  0.28572834,\n",
              "  0.2801253,\n",
              "  0.27763808,\n",
              "  0.27371794,\n",
              "  0.27267507,\n",
              "  0.27501917,\n",
              "  0.26830664,\n",
              "  0.27049172,\n",
              "  0.27097464],\n",
              " 'dense_96_acc': [0.9328511,\n",
              "  0.94384557,\n",
              "  0.95537734,\n",
              "  0.9671184,\n",
              "  0.9737467,\n",
              "  0.976829,\n",
              "  0.97918177,\n",
              "  0.9810368,\n",
              "  0.9821509,\n",
              "  0.9826147,\n",
              "  0.9828918,\n",
              "  0.98377407,\n",
              "  0.98437357,\n",
              "  0.984334,\n",
              "  0.9847242,\n",
              "  0.98480344,\n",
              "  0.9849448,\n",
              "  0.9846394,\n",
              "  0.9848656,\n",
              "  0.98650575,\n",
              "  0.98536897,\n",
              "  0.98559517,\n",
              "  0.9862682,\n",
              "  0.9870939,\n",
              "  0.98702604,\n",
              "  0.9857705,\n",
              "  0.98652273,\n",
              "  0.9867546,\n",
              "  0.98685074],\n",
              " 'dense_96_loss': [0.32772028,\n",
              "  0.20365036,\n",
              "  0.16084084,\n",
              "  0.12592112,\n",
              "  0.10381333,\n",
              "  0.095604286,\n",
              "  0.086806156,\n",
              "  0.08053545,\n",
              "  0.077617705,\n",
              "  0.07598012,\n",
              "  0.0746456,\n",
              "  0.07087194,\n",
              "  0.070226625,\n",
              "  0.07046327,\n",
              "  0.06968306,\n",
              "  0.069577634,\n",
              "  0.068616524,\n",
              "  0.06963058,\n",
              "  0.06889805,\n",
              "  0.062787585,\n",
              "  0.06779886,\n",
              "  0.066081904,\n",
              "  0.063391455,\n",
              "  0.060352944,\n",
              "  0.062101606,\n",
              "  0.06545178,\n",
              "  0.062191863,\n",
              "  0.06409857,\n",
              "  0.06321731],\n",
              " 'dense_97_acc': [0.999163,\n",
              "  0.9995362,\n",
              "  0.9995362,\n",
              "  0.9995362,\n",
              "  0.9995362,\n",
              "  0.9995306,\n",
              "  0.9995136,\n",
              "  0.9995193,\n",
              "  0.99952495,\n",
              "  0.9995193,\n",
              "  0.9995136,\n",
              "  0.9995306,\n",
              "  0.9995193,\n",
              "  0.9995136,\n",
              "  0.99952495,\n",
              "  0.99952495,\n",
              "  0.99952495,\n",
              "  0.99952495,\n",
              "  0.9995306,\n",
              "  0.9995023,\n",
              "  0.9995193,\n",
              "  0.9995306,\n",
              "  0.9995136,\n",
              "  0.9995193,\n",
              "  0.9995193,\n",
              "  0.99952495,\n",
              "  0.99950796,\n",
              "  0.9995362,\n",
              "  0.99950796],\n",
              " 'dense_97_loss': [0.018454274,\n",
              "  0.0049931128,\n",
              "  0.0049731797,\n",
              "  0.004852065,\n",
              "  0.0048169773,\n",
              "  0.0041363956,\n",
              "  0.004261489,\n",
              "  0.004001609,\n",
              "  0.0035921703,\n",
              "  0.0039394707,\n",
              "  0.003815652,\n",
              "  0.0038098919,\n",
              "  0.0036120943,\n",
              "  0.0035993182,\n",
              "  0.003806758,\n",
              "  0.0037525475,\n",
              "  0.003582058,\n",
              "  0.0037764846,\n",
              "  0.0034794402,\n",
              "  0.0035862718,\n",
              "  0.0039751045,\n",
              "  0.003913915,\n",
              "  0.0037733756,\n",
              "  0.0034743797,\n",
              "  0.0036374407,\n",
              "  0.0035555975,\n",
              "  0.0039013152,\n",
              "  0.0036846616,\n",
              "  0.0037144206],\n",
              " 'loss': [5.381997667430332,\n",
              "  2.3953101715667464,\n",
              "  1.4494991258586352,\n",
              "  1.205081045988965,\n",
              "  1.0696319678705446,\n",
              "  0.9984409842444981,\n",
              "  0.939067896184161,\n",
              "  0.8994650229395013,\n",
              "  0.8631245877535437,\n",
              "  0.8603421381917672,\n",
              "  0.8587336177826359,\n",
              "  0.833007924309274,\n",
              "  0.8062287440894147,\n",
              "  0.7974566180299778,\n",
              "  0.7875564112516348,\n",
              "  0.7889867391902152,\n",
              "  0.7594964288255336,\n",
              "  0.7779276284192247,\n",
              "  0.7860662319651341,\n",
              "  0.7490874235688934,\n",
              "  0.7672409935996884,\n",
              "  0.7480974813417421,\n",
              "  0.737719770009545,\n",
              "  0.7131100191906905,\n",
              "  0.7220861878737898,\n",
              "  0.7391341854658464,\n",
              "  0.7068917768895383,\n",
              "  0.7188114368713837,\n",
              "  0.7168129391340571],\n",
              " 'lr': [0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001],\n",
              " 'val_dense_93_acc': [0.6620404,\n",
              "  0.8920918,\n",
              "  0.9274674,\n",
              "  0.93659544,\n",
              "  0.94246596,\n",
              "  0.9426017,\n",
              "  0.9443323,\n",
              "  0.9431446,\n",
              "  0.9529344,\n",
              "  0.95234054,\n",
              "  0.9489133,\n",
              "  0.95152617,\n",
              "  0.95510614,\n",
              "  0.9530532,\n",
              "  0.94200784,\n",
              "  0.9519842,\n",
              "  0.9457405,\n",
              "  0.9506778,\n",
              "  0.95223874,\n",
              "  0.95269686,\n",
              "  0.95101714,\n",
              "  0.949083,\n",
              "  0.9528326,\n",
              "  0.95902544,\n",
              "  0.95269686,\n",
              "  0.93987006,\n",
              "  0.95536065,\n",
              "  0.95373183,\n",
              "  0.9545632],\n",
              " 'val_dense_93_loss': [0.94883263,\n",
              "  0.389874,\n",
              "  0.28918898,\n",
              "  0.25912824,\n",
              "  0.23893496,\n",
              "  0.24026722,\n",
              "  0.2278211,\n",
              "  0.23222555,\n",
              "  0.2025117,\n",
              "  0.21115352,\n",
              "  0.2147041,\n",
              "  0.208381,\n",
              "  0.20418288,\n",
              "  0.21230067,\n",
              "  0.24363552,\n",
              "  0.2085094,\n",
              "  0.23849517,\n",
              "  0.22760817,\n",
              "  0.20888492,\n",
              "  0.21596359,\n",
              "  0.20777269,\n",
              "  0.21764435,\n",
              "  0.21038045,\n",
              "  0.18554299,\n",
              "  0.21650691,\n",
              "  0.24880272,\n",
              "  0.20311825,\n",
              "  0.21050544,\n",
              "  0.20505226],\n",
              " 'val_dense_94_acc': [0.54668385,\n",
              "  0.834965,\n",
              "  0.87607527,\n",
              "  0.9074976,\n",
              "  0.9205619,\n",
              "  0.9209691,\n",
              "  0.9233954,\n",
              "  0.9192385,\n",
              "  0.9332191,\n",
              "  0.9334057,\n",
              "  0.92946947,\n",
              "  0.93150544,\n",
              "  0.93405044,\n",
              "  0.9365106,\n",
              "  0.92643243,\n",
              "  0.93589985,\n",
              "  0.93175995,\n",
              "  0.94085413,\n",
              "  0.9359168,\n",
              "  0.9364258,\n",
              "  0.9328628,\n",
              "  0.93160725,\n",
              "  0.9352042,\n",
              "  0.9444171,\n",
              "  0.9347291,\n",
              "  0.91998506,\n",
              "  0.94051474,\n",
              "  0.93437284,\n",
              "  0.9381564],\n",
              " 'val_dense_94_loss': [1.2280575,\n",
              "  0.5549442,\n",
              "  0.46511248,\n",
              "  0.3775154,\n",
              "  0.32097274,\n",
              "  0.32096156,\n",
              "  0.30229038,\n",
              "  0.32587522,\n",
              "  0.27237457,\n",
              "  0.28491676,\n",
              "  0.2972903,\n",
              "  0.28907564,\n",
              "  0.28857464,\n",
              "  0.2785069,\n",
              "  0.31934175,\n",
              "  0.27167913,\n",
              "  0.29090518,\n",
              "  0.26964325,\n",
              "  0.27347115,\n",
              "  0.29493678,\n",
              "  0.28263184,\n",
              "  0.295569,\n",
              "  0.27815714,\n",
              "  0.24624917,\n",
              "  0.29626602,\n",
              "  0.33777547,\n",
              "  0.26468912,\n",
              "  0.2999817,\n",
              "  0.27163523],\n",
              " 'val_dense_95_acc': [0.66726613,\n",
              "  0.85520625,\n",
              "  0.88871545,\n",
              "  0.892499,\n",
              "  0.8985561,\n",
              "  0.90177983,\n",
              "  0.9054955,\n",
              "  0.90033764,\n",
              "  0.9055973,\n",
              "  0.9090246,\n",
              "  0.9038497,\n",
              "  0.90720916,\n",
              "  0.9087701,\n",
              "  0.90990686,\n",
              "  0.9036801,\n",
              "  0.910348,\n",
              "  0.90700555,\n",
              "  0.9113321,\n",
              "  0.91090786,\n",
              "  0.91046673,\n",
              "  0.9117732,\n",
              "  0.9038497,\n",
              "  0.9117053,\n",
              "  0.9165239,\n",
              "  0.9126894,\n",
              "  0.9040873,\n",
              "  0.9107382,\n",
              "  0.9113321,\n",
              "  0.91212946],\n",
              " 'val_dense_95_loss': [0.92711663,\n",
              "  0.5024025,\n",
              "  0.40426975,\n",
              "  0.38949564,\n",
              "  0.36461884,\n",
              "  0.3463383,\n",
              "  0.3290013,\n",
              "  0.35539946,\n",
              "  0.33673385,\n",
              "  0.32643455,\n",
              "  0.33834162,\n",
              "  0.33453968,\n",
              "  0.33908454,\n",
              "  0.32649913,\n",
              "  0.34787244,\n",
              "  0.32034248,\n",
              "  0.3263728,\n",
              "  0.32273886,\n",
              "  0.31750393,\n",
              "  0.32999992,\n",
              "  0.31962535,\n",
              "  0.3381687,\n",
              "  0.31695276,\n",
              "  0.29259092,\n",
              "  0.31573242,\n",
              "  0.3496604,\n",
              "  0.30886874,\n",
              "  0.32013634,\n",
              "  0.29980606],\n",
              " 'val_dense_96_acc': [0.9390896,\n",
              "  0.9471148,\n",
              "  0.9562938,\n",
              "  0.97090214,\n",
              "  0.97208977,\n",
              "  0.97989446,\n",
              "  0.98116696,\n",
              "  0.9796739,\n",
              "  0.9815063,\n",
              "  0.982694,\n",
              "  0.9812518,\n",
              "  0.9822698,\n",
              "  0.98371196,\n",
              "  0.982677,\n",
              "  0.97989446,\n",
              "  0.9840004,\n",
              "  0.9814045,\n",
              "  0.98393255,\n",
              "  0.9832708,\n",
              "  0.98350835,\n",
              "  0.9831012,\n",
              "  0.97953814,\n",
              "  0.9840004,\n",
              "  0.9845264,\n",
              "  0.98388165,\n",
              "  0.98086154,\n",
              "  0.982677,\n",
              "  0.98362714,\n",
              "  0.9835932],\n",
              " 'val_dense_96_loss': [0.22533086,\n",
              "  0.19795081,\n",
              "  0.17355305,\n",
              "  0.11378207,\n",
              "  0.13044329,\n",
              "  0.08701078,\n",
              "  0.085883036,\n",
              "  0.09300954,\n",
              "  0.08876432,\n",
              "  0.08465721,\n",
              "  0.087126866,\n",
              "  0.08570142,\n",
              "  0.08715791,\n",
              "  0.084108695,\n",
              "  0.095585875,\n",
              "  0.086906575,\n",
              "  0.08566559,\n",
              "  0.085524194,\n",
              "  0.07978445,\n",
              "  0.08721067,\n",
              "  0.08866158,\n",
              "  0.08941875,\n",
              "  0.083696105,\n",
              "  0.075170316,\n",
              "  0.07955569,\n",
              "  0.09513151,\n",
              "  0.08325478,\n",
              "  0.086186685,\n",
              "  0.0750045],\n",
              " 'val_dense_97_acc': [0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044,\n",
              "  0.99927044],\n",
              " 'val_dense_97_loss': [0.007043334,\n",
              "  0.0063945786,\n",
              "  0.0066318605,\n",
              "  0.008662914,\n",
              "  0.008327398,\n",
              "  0.0065610833,\n",
              "  0.007047768,\n",
              "  0.00646026,\n",
              "  0.007826863,\n",
              "  0.0069967345,\n",
              "  0.006996305,\n",
              "  0.0066646403,\n",
              "  0.0070952303,\n",
              "  0.006718649,\n",
              "  0.006120766,\n",
              "  0.0066557582,\n",
              "  0.0075329,\n",
              "  0.007278614,\n",
              "  0.007044817,\n",
              "  0.0072675836,\n",
              "  0.0067854295,\n",
              "  0.0059367735,\n",
              "  0.0063621267,\n",
              "  0.0069889193,\n",
              "  0.0072298935,\n",
              "  0.007612701,\n",
              "  0.007111453,\n",
              "  0.0074794632,\n",
              "  0.0065351035],\n",
              " 'val_loss': [3.3363815720079426,\n",
              "  1.6515655906299234,\n",
              "  1.3387562573753995,\n",
              "  1.1485846619778424,\n",
              "  1.063297366049865,\n",
              "  1.001139099851887,\n",
              "  0.952043774458087,\n",
              "  1.0129698025775546,\n",
              "  0.908211443797554,\n",
              "  0.9141588204728871,\n",
              "  0.9444591077219212,\n",
              "  0.9243624730445837,\n",
              "  0.9260949631416409,\n",
              "  0.9081338447674907,\n",
              "  1.012556244416063,\n",
              "  0.8940932764789227,\n",
              "  0.9489717130862136,\n",
              "  0.9127928159655543,\n",
              "  0.8866890094039515,\n",
              "  0.9353784141322654,\n",
              "  0.9054766274687412,\n",
              "  0.9467371335114794,\n",
              "  0.8955486032191343,\n",
              "  0.8065424536663174,\n",
              "  0.9152910052363753,\n",
              "  1.0389831594087628,\n",
              "  0.8670424202952889,\n",
              "  0.9242894095650345,\n",
              "  0.8580333457937004]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "sW66V6FdVaSn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "if not os.path.exists(\"models\"):\n",
        "  os.mkdir(\"models\")\n",
        "\n",
        "if not os.path.exists(\"models/vgg16_scratch\"):\n",
        "  os.mkdir(\"models/vgg16_scratch\")\n",
        "\n",
        "scratchVGG16_Model(X_train, X_valid, X_test, reshaped_y_train, reshaped_y_valid, reshaped_y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w8HGbPvgBNfR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "modName = 'vgg16_pretrained'\n",
        "\n",
        "if not os.path.exists(\"models\"):\n",
        "  os.mkdir(\"models\")\n",
        "\n",
        "if not os.path.exists(\"models/{}\".format(modName)):\n",
        "  os.mkdir(\"models/{}\".format(modName))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nc3u4h1Oi00k",
        "colab_type": "code",
        "outputId": "bc3ce7ae-15bf-4f76-ada9-4f155226a094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.Session(config = config)\n",
        "tf.keras.backend.set_session(sess)\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "  print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "   print(\"Please install GPU version of TF\")\n",
        "_,row, col,channel = X_train.shape\n",
        "\n",
        "digLen = 5\n",
        "numDigits = 11\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "\n",
        "ptInput = tf.keras.Input(shape = (row,col,channel), name  = 'inputVGGPreTrain')\n",
        "pt_vgg16 = VGG16(include_top = False, weights='imagenet')(ptInput)\n",
        "pt_vgg16 = Flatten(name = 'flatten')(pt_vgg16)\n",
        "pt_vgg16 = Dense(512, activation='relu', name = 'FC1_512')(pt_vgg16)\n",
        "pt_vgg16 = Dense(512, activation='relu', name = 'FC2_512')(pt_vgg16)\n",
        "\n",
        "d1 = Dense(11, activation='softmax')(pt_vgg16)\n",
        "d2 = Dense(11, activation='softmax')(pt_vgg16)\n",
        "d3 = Dense(11, activation='softmax')(pt_vgg16)\n",
        "d4 = Dense(11, activation='softmax')(pt_vgg16)\n",
        "d5 = Dense(11, activation='softmax')(pt_vgg16)\n",
        "out = [d1, d2, d3, d4, d5]\n",
        "\n",
        "vggPreTrain = tf.keras.Model(inputs=ptInput, outputs=out)\n",
        "\n",
        "vggPreTrain.compile(loss = 'sparse_categorical_crossentropy', #ceLoss ,\n",
        "                    optimizer= optim,\n",
        "                    metrics=  ['accuracy']) #[])\n",
        "vggPreTrain.summary()\n",
        "\n",
        "callback = []\n",
        "modName = 'vgg16_pretrained'\n",
        "\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='models/{}/VGGPreTrained.classifier.hdf5'.format(modName),\n",
        "                                               monitor='loss',\n",
        "                                               save_best_only=True,\n",
        "                                               verbose=2)\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'loss',\n",
        "                                              factor = 0.1,\n",
        "                                              verbose = 1,\n",
        "                                              patience= 4,\n",
        "                                              cooldown= 1,\n",
        "                                              min_lr = 0.0001)\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor= 'loss',\n",
        "                                   min_delta=0.000001,\n",
        "                                   patience=5,\n",
        "                                   verbose=1,\n",
        "                                   mode='auto')\n",
        "callback.append(es)\n",
        "callback.append(checkpointer)\n",
        "callback.append(reduce_lr)\n",
        "\n",
        "vgg_pretrained_history = vggPreTrain.fit(x = X_train,\n",
        "                                         y = reshaped_y_train,\n",
        "                                         batch_size = batch_size,\n",
        "                                         epochs=epochs,\n",
        "                                         verbose=1,\n",
        "                                         shuffle = True,\n",
        "                                         validation_data = (X_valid, reshaped_y_valid),\n",
        "                                         callbacks= callback)\n",
        "pickle_file = 'models/{}/history.pickle'.format(modName)\n",
        "pickle.dump(vgg_pretrained_history.history, open(pickle_file, 'wb'))\n",
        "vggPreTrain.save(\"models/{}/model.h5\".format(modName))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default GPU Device: /device:GPU:0\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputVGGPreTrain (InputLayer)   (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "vgg16 (Model)                   multiple             14714688    inputVGGPreTrain[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 512)          0           vgg16[1][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "FC1_512 (Dense)                 (None, 512)          262656      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "FC2_512 (Dense)                 (None, 512)          262656      FC1_512[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 11)           5643        FC2_512[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 11)           5643        FC2_512[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 11)           5643        FC2_512[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 11)           5643        FC2_512[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 11)           5643        FC2_512[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 15,268,215\n",
            "Trainable params: 15,268,215\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 176816 samples, validate on 58939 samples\n",
            "Epoch 1/50\n",
            "176704/176816 [============================>.] - ETA: 0s - loss: 3.9813 - dense_10_loss: 1.0359 - dense_11_loss: 1.5145 - dense_12_loss: 1.1456 - dense_13_loss: 0.2681 - dense_14_loss: 0.0172 - dense_10_acc: 0.6402 - dense_11_acc: 0.4472 - dense_12_acc: 0.6131 - dense_13_acc: 0.9364 - dense_14_acc: 0.9988\n",
            "Epoch 00001: loss improved from inf to 3.97983, saving model to models/vgg16_pretrained/VGGPreTrained.classifier.hdf5\n",
            "176816/176816 [==============================] - 154s 871us/sample - loss: 3.9798 - dense_10_loss: 1.0355 - dense_11_loss: 1.5139 - dense_12_loss: 1.1452 - dense_13_loss: 0.2681 - dense_14_loss: 0.0172 - dense_10_acc: 0.6403 - dense_11_acc: 0.4475 - dense_12_acc: 0.6132 - dense_13_acc: 0.9364 - dense_14_acc: 0.9988 - val_loss: 2.0152 - val_dense_10_loss: 0.4181 - val_dense_11_loss: 0.7486 - val_dense_12_loss: 0.6214 - val_dense_13_loss: 0.2199 - val_dense_14_loss: 0.0072 - val_dense_10_acc: 0.8818 - val_dense_11_acc: 0.7533 - val_dense_12_acc: 0.8039 - val_dense_13_acc: 0.9391 - val_dense_14_acc: 0.9993\n",
            "Epoch 2/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 1.3905 - dense_10_loss: 0.2885 - dense_11_loss: 0.4943 - dense_12_loss: 0.4395 - dense_13_loss: 0.1637 - dense_14_loss: 0.0044 - dense_10_acc: 0.9246 - dense_11_acc: 0.8520 - dense_12_acc: 0.8712 - dense_13_acc: 0.9549 - dense_14_acc: 0.9995\n",
            "Epoch 00002: loss improved from 3.97983 to 1.39050, saving model to models/vgg16_pretrained/VGGPreTrained.classifier.hdf5\n",
            "176816/176816 [==============================] - 150s 849us/sample - loss: 1.3905 - dense_10_loss: 0.2885 - dense_11_loss: 0.4943 - dense_12_loss: 0.4396 - dense_13_loss: 0.1637 - dense_14_loss: 0.0045 - dense_10_acc: 0.9246 - dense_11_acc: 0.8520 - dense_12_acc: 0.8712 - dense_13_acc: 0.9549 - dense_14_acc: 0.9995 - val_loss: 1.0928 - val_dense_10_loss: 0.2367 - val_dense_11_loss: 0.3545 - val_dense_12_loss: 0.3557 - val_dense_13_loss: 0.1389 - val_dense_14_loss: 0.0069 - val_dense_10_acc: 0.9415 - val_dense_11_acc: 0.9028 - val_dense_12_acc: 0.8971 - val_dense_13_acc: 0.9603 - val_dense_14_acc: 0.9993\n",
            "Epoch 3/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.9748 - dense_10_loss: 0.2158 - dense_11_loss: 0.3204 - dense_12_loss: 0.3216 - dense_13_loss: 0.1128 - dense_14_loss: 0.0042 - dense_10_acc: 0.9460 - dense_11_acc: 0.9128 - dense_12_acc: 0.9066 - dense_13_acc: 0.9694 - dense_14_acc: 0.9995\n",
            "Epoch 00003: loss improved from 1.39050 to 0.97477, saving model to models/vgg16_pretrained/VGGPreTrained.classifier.hdf5\n",
            "176816/176816 [==============================] - 150s 847us/sample - loss: 0.9748 - dense_10_loss: 0.2158 - dense_11_loss: 0.3204 - dense_12_loss: 0.3216 - dense_13_loss: 0.1128 - dense_14_loss: 0.0042 - dense_10_acc: 0.9460 - dense_11_acc: 0.9128 - dense_12_acc: 0.9066 - dense_13_acc: 0.9694 - dense_14_acc: 0.9995 - val_loss: 0.9318 - val_dense_10_loss: 0.2207 - val_dense_11_loss: 0.3015 - val_dense_12_loss: 0.2994 - val_dense_13_loss: 0.1030 - val_dense_14_loss: 0.0071 - val_dense_10_acc: 0.9448 - val_dense_11_acc: 0.9216 - val_dense_12_acc: 0.9138 - val_dense_13_acc: 0.9742 - val_dense_14_acc: 0.9993\n",
            "Epoch 4/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.8204 - dense_10_loss: 0.1877 - dense_11_loss: 0.2593 - dense_12_loss: 0.2792 - dense_13_loss: 0.0902 - dense_14_loss: 0.0038 - dense_10_acc: 0.9537 - dense_11_acc: 0.9315 - dense_12_acc: 0.9186 - dense_13_acc: 0.9765 - dense_14_acc: 0.9995\n",
            "Epoch 00004: loss improved from 0.97477 to 0.82035, saving model to models/vgg16_pretrained/VGGPreTrained.classifier.hdf5\n",
            "176816/176816 [==============================] - 149s 842us/sample - loss: 0.8204 - dense_10_loss: 0.1878 - dense_11_loss: 0.2593 - dense_12_loss: 0.2792 - dense_13_loss: 0.0902 - dense_14_loss: 0.0039 - dense_10_acc: 0.9537 - dense_11_acc: 0.9315 - dense_12_acc: 0.9186 - dense_13_acc: 0.9765 - dense_14_acc: 0.9995 - val_loss: 0.8552 - val_dense_10_loss: 0.2013 - val_dense_11_loss: 0.2830 - val_dense_12_loss: 0.2792 - val_dense_13_loss: 0.0859 - val_dense_14_loss: 0.0058 - val_dense_10_acc: 0.9521 - val_dense_11_acc: 0.9286 - val_dense_12_acc: 0.9194 - val_dense_13_acc: 0.9793 - val_dense_14_acc: 0.9993\n",
            "Epoch 5/50\n",
            "176768/176816 [============================>.] - ETA: 0s - loss: 0.7459 - dense_10_loss: 0.1756 - dense_11_loss: 0.2374 - dense_12_loss: 0.2495 - dense_13_loss: 0.0794 - dense_14_loss: 0.0040 - dense_10_acc: 0.9569 - dense_11_acc: 0.9385 - dense_12_acc: 0.9273 - dense_13_acc: 0.9796 - dense_14_acc: 0.9995\n",
            "Epoch 00005: loss improved from 0.82035 to 0.74585, saving model to models/vgg16_pretrained/VGGPreTrained.classifier.hdf5\n",
            "176816/176816 [==============================] - 150s 846us/sample - loss: 0.7459 - dense_10_loss: 0.1755 - dense_11_loss: 0.2374 - dense_12_loss: 0.2495 - dense_13_loss: 0.0794 - dense_14_loss: 0.0040 - dense_10_acc: 0.9569 - dense_11_acc: 0.9385 - dense_12_acc: 0.9273 - dense_13_acc: 0.9796 - dense_14_acc: 0.9995 - val_loss: 0.8156 - val_dense_10_loss: 0.1937 - val_dense_11_loss: 0.2651 - val_dense_12_loss: 0.2649 - val_dense_13_loss: 0.0859 - val_dense_14_loss: 0.0060 - val_dense_10_acc: 0.9537 - val_dense_11_acc: 0.9345 - val_dense_12_acc: 0.9267 - val_dense_13_acc: 0.9804 - val_dense_14_acc: 0.9993\n",
            "Epoch 6/50\n",
            " 29952/176816 [====>.........................] - ETA: 1:53 - loss: 0.6759 - dense_10_loss: 0.1582 - dense_11_loss: 0.2150 - dense_12_loss: 0.2267 - dense_13_loss: 0.0734 - dense_14_loss: 0.0026 - dense_10_acc: 0.9614 - dense_11_acc: 0.9450 - dense_12_acc: 0.9329 - dense_13_acc: 0.9817 - dense_14_acc: 0.9996"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t9ALbbpmY9rm",
        "outputId": "c5ee74e3-f88b-4660-dcba-354d09fa5659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "  random_image_cpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
        "  net_cpu = tf.reduce_sum(net_cpu)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "# Test execution once to detect errors early.\n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise\n",
        "\n",
        "def cpu():\n",
        "  sess.run(net_cpu)\n",
        "  \n",
        "def gpu():\n",
        "  sess.run(net_gpu)\n",
        "  \n",
        "# Runs the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "8.350230318000058\n",
            "GPU (s):\n",
            "0.1842791589999706\n",
            "GPU speedup over CPU: 45x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RBFnn0Z7VCSf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cfdWn94KU6tq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7rlDnKSjUeo0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gfpcByFTsfi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gBkAFJh2TpkH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}